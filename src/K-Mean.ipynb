{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "import pythainlp\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from data_tokenizer import load_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents 269\n",
      "1 clusters\n"
     ]
    }
   ],
   "source": [
    "file_name = 'ผู้บริโภค - TescoLotus.txt'\n",
    "\n",
    "corpus, labels = load_corpus('../data/facebook/' + file_name)\n",
    "\n",
    "len_corpus = len(corpus)\n",
    "print('Total documents', len_corpus)\n",
    "\n",
    "clusters = list(set(labels))\n",
    "print(len(clusters), 'clusters')\n",
    "\n",
    "f = open('../data/facebook/tokenized/tokenized_' + file_name)\n",
    "tokenized_corpus = eval(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: 1313 words\n",
      "filter frequent words: 540 words\n",
      "filter letter words: 539 words\n",
      "filter stop words: 352 words\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(tokenized_corpus)\n",
    "print('origin:', len(dictionary), 'words')\n",
    "\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.7, keep_n=len(dictionary))\n",
    "print('filter frequent words:', len(dictionary), 'words')\n",
    "\n",
    "letter_words = [id for id in range(len(dictionary)) if len(dictionary[id]) <= 1] \n",
    "dictionary.filter_tokens(bad_ids=letter_words)\n",
    "print('filter letter words:', len(dictionary), 'words')\n",
    "\n",
    "stopwords = pythainlp.corpus.stopwords.words('thai')\n",
    "stopwords.append('นี้')\n",
    "dictionary.add_documents([stopwords])\n",
    "stopwords = [dictionary.token2id[word] for word in stopwords]\n",
    "dictionary.filter_tokens(bad_ids=stopwords)\n",
    "print('filter stop words:', len(dictionary), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_corpus]\n",
    "idx_corpus = [dictionary.doc2idx(doc) for doc in tokenized_corpus]\n",
    "\n",
    "temp_corpus = []\n",
    "for doc in idx_corpus:\n",
    "    temp_corpus.append([dictionary[id] for id in doc if id >= 0])\n",
    "idx_corpus = temp_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_doc_size = 0\n",
    "for doc in idx_corpus:\n",
    "    average_doc_size += len(doc)\n",
    "average_doc_size /= len(idx_corpus)\n",
    "average_doc_size = math.ceil(average_doc_size)\n",
    "average_doc_size\n",
    "\n",
    "df = dictionary.dfs\n",
    "filtered_corpus = []\n",
    "for doc in idx_corpus:\n",
    "    new_doc = [(word, df[dictionary.token2id[word]]) for word in doc]\n",
    "    new_doc.sort(reverse=True, key=lambda x: x[1])\n",
    "    new_doc = new_doc[:average_doc_size]\n",
    "    filtered_corpus.append([word for word, df in new_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_corpus = [TaggedDocument(doc, [i]) for i, doc in enumerate(idx_corpus)]\n",
    "model = Doc2Vec(tagged_corpus, vector_size=average_doc_size, window=4, min_count=2, epochs=100)\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "paragraph_vectors = [model.infer_vector(doc) for doc in idx_corpus]\n",
    "paragraph_vectors = pandas.DataFrame(paragraph_vectors, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow(corpus):\n",
    "    new_dict = Dictionary(corpus)\n",
    "\n",
    "    # new_dict.filter_extremes(no_below=2, no_above=1, keep_n=len(new_dict))\n",
    "    # print(len(new_dict))\n",
    "\n",
    "    unique_words = [new_dict[id] for id in range(len(new_dict))]\n",
    "    array = numpy.zeros((len_corpus, len(unique_words)), dtype=float)\n",
    "    \n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc:\n",
    "            array[i, new_dict.token2id[word]] += 1\n",
    "\n",
    "        ## normalization\n",
    "        if len(doc) != 0:\n",
    "            array[i] = numpy.divide(array[i], len(doc))\n",
    "\n",
    "    return pandas.DataFrame(array, columns=unique_words, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster(bow_corpus, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters).fit(bow_corpus)\n",
    "    predicted_labels = kmeans.labels_\n",
    "\n",
    "    result = pandas.DataFrame()\n",
    "    result['comment'] = corpus\n",
    "    result['tokenized_comment'] = idx_corpus\n",
    "    result['label'] = labels\n",
    "    result['predicted_label'] = predicted_labels\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ทำ</th>\n",
       "      <th>พนักงาน</th>\n",
       "      <th>ข้าว</th>\n",
       "      <th>ดี</th>\n",
       "      <th>น้ำ</th>\n",
       "      <th>อี</th>\n",
       "      <th>เครื่อง</th>\n",
       "      <th>เลิก</th>\n",
       "      <th>กก</th>\n",
       "      <th>งง</th>\n",
       "      <th>...</th>\n",
       "      <th>พลังงาน</th>\n",
       "      <th>คอย</th>\n",
       "      <th>แอร์ไม่</th>\n",
       "      <th>สลิป</th>\n",
       "      <th>คู</th>\n",
       "      <th>ปอง</th>\n",
       "      <th>นวมินทร์</th>\n",
       "      <th>สิบ</th>\n",
       "      <th>ห้า</th>\n",
       "      <th>แจก</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ทำ   พนักงาน      ข้าว        ดี       น้ำ        อี   เครื่อง  \\\n",
       "0  0.333333  0.666667  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.166667  0.166667  0.166667  0.166667  0.166667   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.111111  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.111111  0.111111  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       เลิก        กก        งง ...   พลังงาน  คอย  แอร์ไม่  สลิป   คู  ปอง  \\\n",
       "0  0.000000  0.000000  0.000000 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "1  0.166667  0.000000  0.000000 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "2  0.000000  0.111111  0.111111 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "3  0.000000  0.000000  0.000000 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "4  0.000000  0.000000  0.000000 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "\n",
       "   นวมินทร์  สิบ  ห้า  แจก  \n",
       "0       0.0  0.0  0.0  0.0  \n",
       "1       0.0  0.0  0.0  0.0  \n",
       "2       0.0  0.0  0.0  0.0  \n",
       "3       0.0  0.0  0.0  0.0  \n",
       "4       0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusters = 7\n",
    "# bow_corpus = get_bow(idx_corpus)\n",
    "bow_corpus = get_bow(filtered_corpus)\n",
    "result = predict_cluster(bow_corpus, num_clusters)\n",
    "bow_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6], dtype=int32), array([ 42,  18,  22,  20,   8, 137,  22]))\n",
      "\t\tpercent\n",
      "0  |\t42\t1.0\n"
     ]
    }
   ],
   "source": [
    "label_count = numpy.unique(result['predicted_label'], return_counts=True) \n",
    "print(label_count)\n",
    "\n",
    "for cluster in clusters:\n",
    "    print('\\t' + cluster, end='')\n",
    "print('\\tpercent')\n",
    "\n",
    "for label in range(len(clusters)):\n",
    "    print(str(label) + '  |', end='')\n",
    "    \n",
    "    num_max = 0\n",
    "    for cluster in clusters:\n",
    "        loc = result[(result['label'] == cluster) & (result['predicted_label'] == label)]\n",
    "        if len(loc) > num_max:\n",
    "            num_max = len(loc)\n",
    "        print('\\t' + str(len(loc)), end='')\n",
    "    \n",
    "    print('\\t' + str(num_max / label_count[1][label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bd0a68f9544231aa21b0b87de38884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(index=6, options=(1, 2, 3, 4, 5, 6, 7), value=7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 6\n",
      "2 ถุงงง  ถุงมึงบอบบางมากกก ยิ่งเจอน้ำยาซักผ้า น้ำยาปรับผ้านุ่มนะ พร้อมขาดดด\n",
      "3 เราไม่เคยรับถุงเลย แถมได้แต้มกรีนพ้อยไว้ใช้เป็นส่วนลดได้ด้วย ลองดู เตรียมถุงหนาๆไปเองใช้ได้หลายครั้ง\n",
      "11 เลือกผัก เลือกแล้ว เลือกอีก พอมาคิดเงินพนักงานยัดผักใส่ถุงจนผักหัก โอ้ยใจ ใจสลาย\n",
      "13 ราคาสินค้า ตอนโปรโมชั่น บางอันหาไม่เจอ เหมือนพนักงานเอาไปซ่อน ให้ลูกค้าวิ่งไล่หา ไอ้ซั้ซไม่ใช่มอญซ่อนผ้า ปลรปภ บางสาขา หน้าตาดุมาก เวลาเข้าห้างนึกว่าทำไรผิดตลอดเวลา\n",
      "15 ถุงบางมากนี่เรื่องจริง ลูกค้าบางคนเค้าไม่ได้มีรถส่วนตัว หิ้วขึ้นสองแถว ขึ้นรถเมล์ ก็ต้องเข้าใจเค้าด้วย ขอถุงซ้อนเพิ่มก็กลายเป็นเพิ่มการใช้ถุงพลาสติกเข้าไปอีก ก็ทำให้มันหนากว่านี้หน่อยแล้วใช้ใบเดียวไม่ดีกว่าเหรออย่างโลตัสเอกเพรส ส่วนใหญ่คืออยู่ในเขตหมู่บ้าน ลูกค้าเดินมาซื้อ ขี่จักรยานมาซื้อ ถ้าไม่ขอให้ซ้อนถุงนี่หิ้วกลับไม่ถึงบ้านค่ะ บางทีเลยต้องเข้า 711 ถ้าซื้อของที่มีเหมือนกัน\n",
      "23 ควย ค่ะ พนักงานแม่งเกือบทุกคนเลย ไม่มีความคิด วิเคราะห์ แยกแยะไม่ได้ว่าเวลาลูกค้าซื้อผัก ซื้อหมูบด น้ำยาล้างจาน น้ำปลา หรืออะไรก็แล้วแต่ ถุงมึงมีใบใหญ่สุดแค่ไหนมึงเอามาใส่แม่งรวมกันหมดทุกอย่าง ผักกูเลือกดีๆเอาไม่ช้ำ อีดอกเอาไว้ล่างสุด เอาแพ็คหมูบดทับ\n",
      "60 รถเข็นช่วงเติมสินค้า ไม่คิดจะหลบลูกค้าบางเลย ขนาดขอทางหน่อย หันมามองที่ สะพรึงมากกกก กลัวเลยไม่ซื้อเลย\n",
      "65 หมูสับในโลตัสเอ็กเพรสบางไปค่ะ บดซะแห้งเกิน ผักช้ำๆ บางอันก็เสียแล้วจริงๆ ทิ้งเถอะค่ะ อย่าป้ายเหลืองเลย\n",
      "89 ซ้อนถุงให้หน่อยเถอะ ซื้อนมยาปรับผ้านุ่ม ยังเดินไม่พ้นแคชเชียร์เลย ไอ่เขี้ยงถุงขาด\n",
      "93 ไม่มีถุงใส่ของใบใหญ่บริการลูกค้า เวลาซื้อสินค้าชิ้นใหญ่ๆ เช่น กระดาษทิชชู่แพ็ค 24 ม้วน หมอน และอื่นๆ ไม่มีถุงใหญ่ใส่ให้ วิธีการแก้ไขของบางสาขาคือเอาสก็อตเทปใหญ่แปะ แล้วหิ้วสก็อตเทปเอา คือแบบน่ารำคาญมากตรงจุดนี้ คือกะอีแค่ถุงใส่ของไม่มีให้ลูกค้า ตลกมาก เวลาไม่ได้เอารถไปก็คือลำบากมาก ต้องหอบหิ้วของใหญ่ๆ กลับบ้าน บางทีซื้อหลายอย่างยิ่งหนักเข้าไปอีก ควรปรับปรุงด่วน เพราะซูเปอร์มาร์เก็ตคู่แข่งเค้ามีกันทุกเจ้าค่ะ\n",
      "106 ถุงบางมาก บางทีก้อไม่ชอบซ้อนถุงให้ ซื้อของชิ้นใหญ่ถุงก็ไม่มีใส่ให้ ครั้งนู้นซื้อหมอนอิงใบใหญ่  ออกมาฝนตก หมอนไม่หุ้มพลาสติก ต้อง้อาเสื้อกันฝนมาห่อหมอน  เห็นใจคนมามอเตอร์ไซต์ด้วยค่ะ\n",
      "114 ไปชื้อนมให้ลูกคือกล่องนมมันใหญ่มากใหญ่กว่าถุงมึงอีกอะเพิ่มขนาดถุงและเพิ่มความหนาอีกนีสนึงนะ\n",
      "139 โดยรวมแล้วคือ  1ถุงบางเคยหิ้วถุงใส่ขวดซอส ถุงขาดขวดแตก ขนาดข้าวถุง 5 กิโลใส่ให้แค่ชั้นเดียว ขอถุงซ้อนเพิ่ม  มีแลตาใส่พร้อมกับฟึดฟัดด้วย   2ช่องคิดเงินมีเยอะแต่ใช้จริงไม่ถึง 50  3พนักงานโยนของใส่ถุง ไม่ได้นึกถึงว่าของจะพังเสียหาย บางทีเห็นปล่อยให้กลิ้งจากมือลงถุง   4พนักงานหน้าไม่รับแขกโดยเฉพาะแผนกคิดเงิน    ที่ไหนเป็นแบบนี้บ้าง ที่นี่สาขาพะเยาจ้า\n",
      "146 ง่ายๆ ของบอกลดพนักงานพากันซ่อนของแล้วบอกให้คนที่บ้านมาเอา ลูกค้าหาไม่เจอหรอก สรุปปานเล่นซ้อนหากันน๊อ\n",
      "148 เครื่องคิดเงินต่อคิวจนเหนื่อย ปล่อยว่างไว้ทำไม แถมเรื่องถุงด้วย บางยิ่งกว่าถุงยางอีกความยืดหนุ่นหามีไม่พอขอซ้อนถุงพนักงานจะทำหน้าไม่พอใจทำไม กลัวถุงขาด ให้ๆไปเถอะ\n",
      "157 ไช้อยากไห้ถุงหนาเวลาไปชื่อนำ้แดงทีไรถึงแถบขาดไส่มอเตอร์ไชร์มาแถบไม่ถึงบ้าน\n",
      "165 ตอนเลือกซื้อผัก เลือกเเล้ว เลือกอีก พอจ่ายตังค์ใส่ถุง ผักหักสะงั้น\n",
      "173 ถุงโครตบาง ขอซ้อนถุง แม่งหวงไปไหน หวงไว้กินหรอค่ะ\n",
      "187 เลิกแจกถุงค่ะ แนะนำให้ขายถุงพลาสติกแทน ลดโลกร้อนดีค่ะ\n",
      "195 ถุงบางได้อีกโดนมุมของถุงน้ำยาปรับผ้านุ่มก็ขาดจะหมดอยู่แล้ว\n",
      "217 ถุงบางมากๆขนาดซ้อนกัน2ใบยังขาดเลย\n",
      "258 เลิกแจกถุงพลาสติก\n"
     ]
    }
   ],
   "source": [
    "comment_widget = widgets.ToggleButtons(\n",
    "    options=[num + 1 for num in range(num_clusters)],\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    ")\n",
    "\n",
    "def on_comment_widget_click(change):\n",
    "    clear_output()\n",
    "    display(comment_widget)\n",
    "    print('cluster', change['new'])\n",
    "    for index, value in result[result['predicted_label'] == change['new']]['comment'].iteritems():\n",
    "        print(index, value)\n",
    "\n",
    "comment_widget.observe(on_comment_widget_click, names='index')\n",
    "on_comment_widget_click({'new' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c060cfae96b942c4a63742bdfe7953b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(options=(1, 2, 3, 4, 5, 6, 7), value=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['พนักงาน', 'พนักงาน', 'โลตัส', 'โลตัส', 'ทำ', 'เอ็กเพลส', 'พนักงาน', 'คน', 'ทำ', 'ขาย', 'คน', 'คน', 'เวลา', 'กิน', 'ข้าว', 'ผม', 'คน', 'พนักงาน', 'เหมือน', 'พนักงาน', 'คน', 'ผม', 'รู้', 'พนักงาน', 'ตั้งใจ', 'ทำ', 'งาน', 'คน']\n",
      "4 ['ทำ', 'เดือน', 'พนักงาน', 'คน', 'คน', 'คน', 'นึง', 'พัน', 'เช้า', 'เย็น']\n",
      "7 ['คน', 'คน', 'คน', 'ดี', 'คน', 'ดี', 'ผม', 'โลก', 'ผม', 'ทำ', 'งาน', 'บริการ', 'เหมือน', 'ยืน', 'จุด', 'ยืน', 'รู้', 'พนักงาน', 'เหมือน', 'ปรับปรุง', 'ดี', 'ปรับปรุง', 'ตัว', 'ดี', 'ดี']\n",
      "8 ['พนักงาน', 'ทำ', 'หน้า', 'ตูด', 'คน', 'เหมือน', 'บังคับ', 'ทำ', 'งาน', 'งั้น']\n",
      "12 ['มารยาท', 'พนักงาน', 'เซเว่น', 'คุณภาพ', 'ดี', 'นึง', 'เหี้ย', 'คู่']\n",
      "17 ['พนักงาน', 'เอ็กเพรส', 'สาขา', 'หน้า', 'บูด', 'ทำ', 'งาน', 'กกกกก', 'ถาม', 'รู้', 'เรื่อง', 'ดี']\n",
      "19 ['สาขา', 'หน้า', 'สาขา', 'แผนก', 'ใด', 'สีหน้า', 'ท่าทาง', 'บริการ', 'เซอร์วิสมายด์', 'ทำ', 'ปล่อย', 'ตอน', 'ทำ', 'ซื้อ', 'ห้าง']\n",
      "24 ['สาขา', 'แย่', 'ซื้อ', 'ลูก', 'ยืน', 'รอ', 'เงิน', 'ยืน', 'คุย', 'สอง', 'คน', 'หน้า', 'สัก', 'ยืน', 'รอ', 'นาที', 'ตอน', 'ด่า', 'เหมือน', 'ทำ', 'เดิน']\n",
      "28 ['พนักงาน', 'เหมือน', 'ทำ', 'งาน', 'หน้า', 'งอ', 'คน', 'รัก', 'ดี']\n",
      "38 ['โลตัส', 'เอ็กเพรส', 'พนักงาน', 'หน้า', 'หงิก', 'ถาม', 'รู้', 'เรื่อง', 'เรื่อง', 'คุย', 'คุย', 'รู้', 'เรื่อง', 'เดิน', 'ลูกค้า', 'ร่ม']\n",
      "51 ['โลตัส', 'แทบ', 'สาขา', 'แคชเชียร์', 'คน', 'ยืน', 'เคาเตอร์', 'มัว']\n",
      "52 ['ปรับปรุง', 'มารยาท', 'พนักงาน', 'สิ', 'มารยาท', 'นึก', 'ทำ', 'งาน', 'ห้าง', 'เหรอ', 'คน']\n",
      "53 ['งาน', 'กะ', 'นึง', 'คน', 'งาน', 'ลูกค้า', 'งาน', 'ทำ', 'กะ', 'กะ', 'หา', 'ทำ', 'งาน', 'โลตัส', 'เอ็กเพรส', 'ค่า', 'เเต่', 'ทำ', 'งาน', 'กะ', 'ค่า', 'เกลียด', 'ตอน', 'ซ่อม', 'รายงาน', 'ปล่อย', 'บ้า', 'กำกับ', 'กล้อง']\n",
      "54 ['พนักงาน', 'เหมือน', 'ทำ', 'งาน', 'หน้า', 'ลูกค้า', 'ถาม', 'ก้อ', 'รู้', 'เรื่อง']\n",
      "61 ['พนักงาน', 'ใบ', 'กำกับ', 'ภาษี', 'ทำ', 'หน้า', 'ผัว', 'ดี', 'ยาง', 'หี', 'ตัว', 'ทำ', 'งาน', 'บริการ', 'งี่', 'เง่า', 'ใส่', 'ลูกค้า', 'อ่ะ']\n",
      "63 ['โลตัส', 'เอ็กเพรส', 'แย่', 'หน้า', 'กะ', 'ผัว', 'ทิ้ง', 'อบรม', 'ดี']\n",
      "73 ['พนักงาน', 'หน้า', 'บริการ', 'ลูกค้า', 'หน้าตา', 'บริการ', 'ลูกค้า', 'หน้า', 'กก', 'กุ', 'โลตัส', 'ต่ำ', 'ตา', 'เดิน', 'เจอ', 'หน้า', 'พนักงาน']\n",
      "81 ['พนักงาน', 'บริการ', 'แย่', 'หน้า', 'เหมือน', 'ตูด', 'ยิ้ม', 'ยิ้ม', 'ตอบ', 'พูดจา', 'ทำ', 'ทำ', 'สนใจ', 'ลูกค้า', 'เคาเตอร์', 'สาม', 'คน', 'ขาย', 'คน', 'ยืน', 'เพื่อน', 'มั้ง', 'ระบุ', 'สาขา']\n",
      "82 ['คน', 'พื้นที่', 'ฟัง', 'คน', 'ตัว', 'กุ', 'คน']\n",
      "83 ['บริการ', 'พนักงาน', 'ลูกค้า', 'บริการ', 'ว่าง', 'แลก', 'พนักงาน', 'คอย', 'บริการ', 'ห้าง', 'บ้าน', 'ยืน', 'จุด', 'แทน', 'ลูกค้า']\n",
      "87 ['มารยาท', 'พนักงาน', 'ดี', 'เดิน', 'คน', 'กิน', 'หัว', 'ยิ้ม', 'สัก', 'มั้ง', 'เหอะ', 'แม่']\n",
      "88 ['โดน', 'ตอน', 'เด็ก', 'แรง', 'ชอบ', 'หัว', 'ตอน', 'หยิบ', 'ใบ', 'รายงาน', 'พฤติกรรม', 'พนง', 'คน', 'รายงาน', 'เดี๋ยว', 'เจอ', 'พนง', 'คน', 'แถม', 'รู้', 'ตอน', 'เดือน', 'อบรม', 'นิสัย', 'สัก', 'ทำ', 'งาน']\n",
      "92 ['พนักงาน', 'พูดจา', 'เหมือน', 'ทะเลาะ', 'ผัว', 'กวน', 'บ้าน', 'อย่า', 'ทำ', 'งาน']\n",
      "96 ['เจอ', 'ทำ', 'งาน', 'พนักงาน', 'โลตัส', 'พนักงาน', 'ตูด', 'เจอ', 'พนักงาน', 'หน้า', 'ใส่', 'ลูกค้า', 'คน', 'ใส่', 'ใส่', 'โลตัส', 'เขต', 'ระบุ', 'เดี๋ยว', 'โดน']\n",
      "99 ['บริการ', 'ลูกค้า', 'เต็มใจ', 'พูดจา', 'เหมือน', 'งั้น', 'อารมณ์', 'ใบ', 'กำกับ', 'ภาษี', 'เหมือน', 'เงิน']\n",
      "101 ['คุย', 'เสียง', 'เงิน', 'พูดจา', 'เหี้ย', 'สัตว์', 'หน้า', 'ลค']\n",
      "111 ['โลตัส', 'บริการ', 'ดี', 'พนักงาน', 'ยิ้มแย้ม', 'ดี', 'อี', 'พนักงาน', 'คน', 'นึง', 'หน้า', 'เหมือน', 'โดน', 'ถาม', 'ควย', 'ตอบ', 'สงสัย', 'หี', 'อีดอก', 'ทราบ']\n",
      "113 ['จ่าย', 'เงิน', 'ไหว้', 'ไหว้', 'หัว', 'ลูกค้า']\n",
      "121 ['โลตัส เอ็กเพรส', 'พนักงาน', 'ยิ้มแย้ม', 'เหมือน', 'รัก', 'งาน', 'บริการ']\n",
      "123 ['ไหว้', 'มือ', 'ไหว้', 'ก้อ', 'รู้', 'โดน', 'บังคับ', 'ไหว้', 'คน', 'แม่']\n",
      "127 ['พนักงาน', 'ห่วย', 'คุย', 'สนใจ', 'ลค', 'ดึง', 'หน้า', 'เหมือน', 'ทะเลาะ', 'ผัว', 'เฮ้ย']\n",
      "132 ['แรง', 'เรื่อง', 'พนักงาน', 'แคชเชียร์', 'คน', 'ลูกค้า', 'สนใจ', 'เงิน', 'เครื่อง', 'คน', 'หน้า', 'ส้น', 'ตีน', 'ลูกค้า', 'แคชเชียร์', 'บริการ', 'แทบ', 'สาขา']\n",
      "138 ['โลตัส', 'กรุณา', 'อบรม', 'มารยาท', 'พนักงาน', 'ทำ', 'งาน', 'เวลา', 'ลูกค้า', 'หัว', 'ช่อง', 'เงิน', 'หัว', 'ร้าน', 'พูดจา', 'สีหน้า', 'ท่าทาง', 'พนักงาน', 'คน', 'ปรับปรุง', 'ทำ', 'หน้า', 'เหมือน', 'เวลา', 'ลูกค้า', 'แจ้ง', 'ทำ', 'หน้าตา', 'พอใจ', 'ใส่', 'อารม', 'ลูกค้า']\n",
      "145 ['สาขา', 'เรื่อง', 'มารยาท', 'ลูกค้า', 'เหมือน', 'ลูกค้า', 'ขอฟรี', 'แย่', 'ผม', 'เหมือน']\n",
      "149 ['พนักงาน', 'ดึง', 'หน้า', 'ใส่', 'ดึง', 'หน้า', 'ใส่', 'พูดจา', 'คน', 'ดี', 'รัก', 'อบรม']\n",
      "153 ['งาน', 'เหมือน', 'บริการ', 'พนักงาน', 'ลูกค้า', 'เหรอ', 'กรุณา', 'ตัว']\n",
      "191 ['พนักงาน', 'หน้าตา', 'เหมือน', 'กิน', 'ข้าว', 'บูด']\n",
      "200 ['โลตัส', 'นิสัย', 'พนักงาน', 'แย่', 'แทบ', 'สาขา']\n",
      "203 ['โลตัส', 'พนักงาน', 'หน้า', 'หงิก', 'ส้น', 'ตีน']\n",
      "213 ['โทร', 'เวลา', 'คน', 'งาน', 'โลตัส', 'สาขา']\n",
      "226 ['อบรม', 'พนักงาน', 'ทำ', 'งาน', 'อ่ะ']\n",
      "231 ['พนักงาน', 'คน', 'พูดจา', 'แย่', 'โดน', 'ตะคอก', 'นึง']\n"
     ]
    }
   ],
   "source": [
    "token_widget = widgets.ToggleButtons(\n",
    "    options=[num + 1 for num in range(num_clusters)],\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    ")\n",
    "\n",
    "def on_token_widget_click(change):\n",
    "    clear_output()\n",
    "    display(token_widget)\n",
    "    for index, value in result[result['predicted_label'] == change['new']]['tokenized_comment'].iteritems():\n",
    "        print(index, value)\n",
    "\n",
    "token_widget.observe(on_token_widget_click, names='index')\n",
    "on_token_widget_click({'new' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senior-project",
   "language": "python",
   "name": "senior-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
