{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "import pythainlp\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from data_tokenizer import load_corpus\n",
    "\n",
    "from model.new_sdc import NewSDC\n",
    "from model.sdc import SDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents 229\n"
     ]
    }
   ],
   "source": [
    "file_name = 'เข็นเด็กขึ้นภูเขา - ฝุ่น'\n",
    "\n",
    "corpus = load_corpus('../data/' + file_name + '.txt')\n",
    "\n",
    "print('Total documents', len(corpus))\n",
    "\n",
    "f = open('../data/tokenized/tokenized_' + file_name + '.txt')\n",
    "tokenized_corpus = eval(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: 1402 words\n",
      "filter frequent words: 658 words\n",
      "filter letter words: 654 words\n",
      "filter stop words: 428 words\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(tokenized_corpus)\n",
    "print('origin:', len(dictionary), 'words')\n",
    "\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.7, keep_n=len(dictionary))\n",
    "print('filter frequent words:', len(dictionary), 'words')\n",
    "\n",
    "letter_words = [id for id in range(len(dictionary)) if len(dictionary[id]) <= 1] \n",
    "dictionary.filter_tokens(bad_ids=letter_words)\n",
    "print('filter letter words:', len(dictionary), 'words')\n",
    "\n",
    "stopwords = pythainlp.corpus.stopwords.words('thai')\n",
    "stopwords.extend(['นี้'])\n",
    "dictionary.add_documents([stopwords])\n",
    "stopwords = [dictionary.token2id[word] for word in stopwords]\n",
    "dictionary.filter_tokens(bad_ids=stopwords)\n",
    "print('filter stop words:', len(dictionary), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx_corpus = [dictionary.doc2idx(doc) for doc in tokenized_corpus]\n",
    "\n",
    "temp_corpus = []\n",
    "for doc in idx_corpus:\n",
    "    temp_corpus.append([dictionary[id] for id in doc if id >= 0])\n",
    "idx_corpus = temp_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_doc_size = 0\n",
    "for doc in idx_corpus:\n",
    "    average_doc_size += len(doc)\n",
    "average_doc_size /= len(idx_corpus)\n",
    "average_doc_size = math.ceil(average_doc_size)\n",
    "\n",
    "df = dictionary.dfs\n",
    "filtered_corpus = []\n",
    "for doc in idx_corpus:\n",
    "    new_doc = [(word, df[dictionary.token2id[word]]) for word in doc]\n",
    "    new_doc.sort(reverse=True, key=lambda x: x[1])\n",
    "    new_doc = new_doc[:average_doc_size]\n",
    "    filtered_corpus.append([word for word, df in new_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(corpus, weight):\n",
    "    dictionary = Dictionary(corpus)\n",
    "#     dictionary.filter_extremes(no_below=2, no_above=1, keep_n=len(dictionary))\n",
    "\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in corpus]\n",
    "    if weight == 'normal':\n",
    "        weight_corpus = bow_corpus\n",
    "    elif weight == 'tfidf':\n",
    "        tfidf = TfidfModel(bow_corpus, smartirs='ltc')\n",
    "        weight_corpus = [tfidf[doc] for doc in bow_corpus]\n",
    "\n",
    "    unique_words = [dictionary[id] for id in range(len(dictionary))]\n",
    "    array = numpy.zeros((len(corpus), len(unique_words)), dtype=float)\n",
    "    for i, doc in enumerate(weight_corpus):\n",
    "        for id, score in doc:\n",
    "            array[i, id] = score\n",
    "\n",
    "        if weight == 'normal' and len(doc) != 0:\n",
    "#             array[i] = numpy.divide(array[i], len(idx_corpus[i]))\n",
    "            array[i] = numpy.divide(array[i], len(doc))\n",
    "    \n",
    "    return pandas.DataFrame(array, columns=unique_words, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result(predicted_labels, marks):\n",
    "    result = pandas.DataFrame()\n",
    "    result['comment'] = corpus\n",
    "    result['tokenized_comment'] = filtered_corpus\n",
    "    result['predicted_label'] = predicted_labels\n",
    "    if marks:\n",
    "        result['marks'] = marks\n",
    "    else:\n",
    "        result['marks'] = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cluster(onehot_corpus, result):\n",
    "    label_count = numpy.unique(result['predicted_label'])\n",
    "    num_cluster = label_count[-1] + 1\n",
    "\n",
    "    clusters = [[] for i in range(num_cluster)]\n",
    "    corpus_centroid = []\n",
    "    for i, label in result['predicted_label'].iteritems():\n",
    "        clusters[label].append(numpy.array(onehot_corpus.iloc[i]))\n",
    "        corpus_centroid.append(numpy.array(onehot_corpus.iloc[i]))\n",
    "    corpus_centroid = numpy.mean(corpus_centroid, axis=0).reshape(1, -1)   \n",
    "\n",
    "#     print('\\tIntra cluster sim\\tInter cluster sim\\tIntra / Inter')\n",
    "    compactness = 0\n",
    "    centroids = []\n",
    "    for i in range(num_cluster):\n",
    "        size = len(clusters[i])\n",
    "        if size != 0:\n",
    "            centroid = numpy.mean(clusters[i], axis=0)\n",
    "            centroids.append(centroid)\n",
    "            centroid = centroid.reshape(1, -1)\n",
    "            similarities = cosine_similarity(centroid, clusters[i])\n",
    "            compactness += numpy.sum(similarities)\n",
    "\n",
    "#             intra = numpy.sum(similarities) / size\n",
    "#             inter = cosine_similarity(centroid, corpus_centroid)[0][0]\n",
    "#             print(i, end='\\t')\n",
    "#             print(intra, end='\\t')\n",
    "#             print(inter, end='\\t')\n",
    "#             print(intra / inter)\n",
    "    return compactness, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 7\n",
    "eps = 0.32\n",
    "expand_rate = 0.05\n",
    "epoch = 15\n",
    "\n",
    "onehot_corpus = get_onehot(filtered_corpus, 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.4605630861508\n",
      "[41 25  8  7 14 10 13 35 14  9 20  7  9  9  8]\n"
     ]
    }
   ],
   "source": [
    "max_compactness = 0\n",
    "for i in range(epoch):\n",
    "    model = NewSDC()\n",
    "    _tpredicted_labels, marks = model.predict(onehot_corpus, min_samples, eps, expand_rate)\n",
    "\n",
    "#     model = SDC()\n",
    "#     _tpredicted_labels, marks = model.predict(onehot_corpus, min_samples, eps, expand_rate)\n",
    "    \n",
    "#     marks = None\n",
    "    \n",
    "#     model = DBSCAN(metric='cosine', eps=eps, min_samples=min_samples).fit(onehot_corpus)\n",
    "#     _tpredicted_labels = model.labels_ + 1\n",
    "\n",
    "#     model = KMeans(n_clusters=14).fit(onehot_corpus)\n",
    "#     _tpredicted_labels = model.labels_\n",
    "    \n",
    "    _tresult = generate_result(_tpredicted_labels, marks)\n",
    "    compactness, _tcentroids = eval_cluster(onehot_corpus, _tresult)\n",
    "    \n",
    "    if compactness > max_compactness:\n",
    "        max_compactness = compactness\n",
    "        predicted_labels = _tpredicted_labels\n",
    "        result = _tresult\n",
    "        centroids = _tcentroids\n",
    "        \n",
    "print(max_compactness)\n",
    "label_count = numpy.unique(result['predicted_label'], return_counts=True)[1]\n",
    "num_cluster = len(label_count)\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative New SDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.9490639190021\n",
      "[57 55 26 24 12 10  8 10 15 12]\n",
      "104.3832485532235\n",
      "[57 71 22 22 16  8  8  8  8  9]\n",
      "102.59673604127416\n",
      "[58 74 18 22 24  8  8  8  9]\n",
      "102.31923594575228\n",
      "[60 75 16 22 23  8  8  8  9]\n",
      "102.03194738654726\n",
      "[61 76 16 22 21  8  8  8  9]\n",
      "101.99221692781013\n",
      "[62 77 15 22 20  8  8  8  9]\n",
      "102.06485127082063\n",
      "[62 77 14 23 20  8  8  8  9]\n"
     ]
    }
   ],
   "source": [
    "centroids = None \n",
    "prev_label_count = None\n",
    "while True:\n",
    "    model = NewSDC()\n",
    "    predicted_labels, marks = model.predict(onehot_corpus, min_samples, eps, expand_rate, seeds=centroids)\n",
    "    \n",
    "    result = generate_result(predicted_labels, marks)\n",
    "    compactness, centroids = eval_cluster(onehot_corpus, result)\n",
    "    \n",
    "    label_count = numpy.unique(result['predicted_label'], return_counts=True)[1]\n",
    "    if numpy.array_equal(label_count, prev_label_count):\n",
    "        break\n",
    "    prev_label_count = label_count\n",
    "    centroids = centroids[1:]\n",
    "    \n",
    "    print(compactness)\n",
    "    print(label_count)\n",
    "num_cluster = len(label_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "2 1 0.595633751496191\n",
      "[0, 1, 1, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "sims = cosine_similarity(centroids)\n",
    "new_labels = [i for i in range(num_cluster)]\n",
    "print(new_labels)\n",
    "for i, row in reversed(list(enumerate(sims))):\n",
    "    for j, value in reversed(list(enumerate(row[:i + 1]))):\n",
    "        if i != j and value >= eps - eps / 20:\n",
    "            print(i, j, value)\n",
    "            base = min(new_labels[i], new_labels[j])\n",
    "            new_labels[j] = base\n",
    "            new_labels = [base if label == new_labels[i] else label for label in new_labels]\n",
    "print(new_labels)\n",
    "\n",
    "grouped_labels = numpy.zeros(len(corpus))\n",
    "for i, label in enumerate(predicted_labels):\n",
    "    grouped_labels[i] = new_labels[label]\n",
    "new_result = generate_result(grouped_labels, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Widget:\n",
    "    def __init__(self, result, column_name):\n",
    "        self.result = result\n",
    "        self.column_name = column_name\n",
    "        \n",
    "        label_count = numpy.unique(result['predicted_label'])\n",
    "        self.widget = widgets.ToggleButtons(\n",
    "            options=[int(num) for num in label_count],\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "        )\n",
    "        \n",
    "        self.widget.observe(self.on_click, names='index')\n",
    "        self.on_click({'new' : 0})\n",
    "        \n",
    "    def on_click(self, change):\n",
    "        clear_output()\n",
    "        display(self.widget)\n",
    "        new = self.widget.options[change['new']]\n",
    "        for index, value in self.result[self.result['predicted_label'] == new].iterrows():\n",
    "            if value['marks'] == 0:\n",
    "                print(\"@\", end=\"\")\n",
    "            elif value['marks'] == 1:\n",
    "                print(\"*\", end=\"\")\n",
    "            print(index, value[self.column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.06485127082063\n",
      "[62 77 14 23 20  8  8  8  9]\n"
     ]
    }
   ],
   "source": [
    "# result.to_csv('../data/results/new_sdc/' + file_name + '.csv', index=False)\n",
    "\n",
    "# result = pandas.read_csv('../data/results/new_sdc/' + file_name + '.csv')\n",
    "\n",
    "print(eval_cluster(onehot_corpus, result)[0])\n",
    "print(numpy.unique(result['predicted_label'], return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0ec72b8b8444109e8bd8d98b7509d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(options=(0, 1, 3, 4, 5, 6, 7, 8), value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 หงุดหงิดมากอะ รร ลูกอยู่ตรงปทุมวัน เขตนี้ควันนรกมากเลยอะ ต้องพยายามให้ใส่หน้ากาก ไม่รู้จะช่วยได้แค่ไหน ให้ใส่แบบกันเยอะๆ นางก็บ่น แต่นางก็ใส่แหละ\n",
      "6 วันนี้เขตโรงเรียนลูก 249 รร.ไม่หยุด แม่หยุดเองเลยค่ะ\n",
      "15 ที่น่าสังเวคือยังมีคนจำนวนหนึ่งมองว่าพวกเราบ้าประสาทตื่นตูมกันอยู่เลย ใส่หน้ากากก็โดนมองเหมือนสัตว์ประหลาด\n",
      "17 T T ควรประกาศภัยพิบัติได้แล้วนะครับ  ผลกระทบต่อสุขภาพระยะยาวแบบเลี่ยงไม่ได้ สุดท้ายจะกลายเป็นภาระมหาศาลของระบบสาธารณสุขเลย\n",
      "22 ตอนนี้รัดทะบาน ห่วงแต่การสืบทอดอำนาจ สนจัยอะไรที่ไหนกัน ทนได้ก้อทนกันไป ทนไม่ได้ก้อทำอะไรไม่ได้ ประเทศไทย จะไม่มีคนดีๆ มาบริหารประเทศเลยหรอ\n",
      "34 นอกจากการหายใจ ตอนนี้เริ่มแสบตา ระคายเคืองตา  แล้วก็คันที่ผิวหนังบ่อยขึ้นค่ะ ไม่รู้เราคิดไปเองไหม แต่ปกติผิวหนังไม่เคยแพ้อะไรเลย\n",
      "41 นานๆจะเห็นหมอขึ้น ดูเหมือนนายกจะออกมาตราการ มา 9ข้อ แล้วนะครับ แต่อ่านๆดูบางข้อก็รู้สึกมันเป็นเรื่องที่ภาวะปกติก็ต้องทำอยู่แล้วรึเปล่า\n",
      "42 เชียงใหม่ ช่วงปลายกุมภา  ถึงกลางเมษาจะเลวร้ายมา 3 ปี  มีปีนึงที่รณรงค์   ช่วยกันเต็มที่ ลดลงได้บ้าง  แต่พอลดลง  บนป่าก็มาเผาเหมือนเดิม  เศร้าใจมากค่ะ\n",
      "50 ท่าทีของผู้ใหญ่ในบ้านเมืองยังดูอายที่จะประกาศว่าจริงๆมันวิกฤตแล้ว ยังคงพยายามสร้างภาพ ให้ข่าวว่ามันไม่ได้อันตรายขนาดนั้น ตัวเลข PM2.5 ของหน่วยงานรัฐ น้อยกว่าของเว็ปไซต์ที่เป็นที่ยอมรับในระดับสากลเยอะ 😓😓😓\n",
      "54 This shows everything about Thailand\n",
      "56 เห็นด้วยเป็นอย่างยิ่ง มีแต่พูดกันออกสื่อไม่เคยลงมาดูพื้นที่จริงๆ ว่าปัญหามันคืออะไร มาดูถนนกาญจนฯ จ.สมุทรสาครสิคะ ว่าปัญหามันคืออะไร ไม่ใช่นั่งเทียนพูดๆๆๆๆๆ ไป เหนื่อยใจค่ะ ย้อนกลับมาแก้ไขและป้องกันลูกๆเรา ด้วยตัวเราเองค่ะ -_-||\n",
      "63 เสนอเพิ่มว่าควรปิดเทอมหน้าฝน เพราะทั้งเด็กทั้งผู้ใหญ่เดินทางกันลำบากมาก เด็กก็ป่วยง่ายในช่วงนั้นค่ะ รัฐบาลควรคิดแก้ไขเพื่อเด็กๆบ้างก็ดี ถึงจะแก้อะไรไม่ค่อยได้เรื่อง\n",
      "67 ขออนุญาตค่ะด่วน!!!!!!!!!!!!!!!!!!!!หน้ากาก N95ป้องกันฝุ่นชนิด PM2.5 micronชนิดมีวาล์ป ทำให้หายใจไม่ลำบากมาก ร่วมกับมีคาร์บอนเคลือบ ช่วยในการกรองมากขึ้นราคาชิ้นละ 40 บาทค่าส่ง  ลงทะเบียน 30 บาท            EMS           50 บาท            รพ. รามา    ฟรี            หน้า รร สตรีนนท์ ฟรีหมดล็อตนี้หมดเลยสนใจ ib มาเลยค่ะ ของมาถึงวันจันทร์\n",
      "71 ข้อเสนอคุณหมอดีมากๆค่ะ เห็นด้วยทุกข้อและ implement ได้ไม่ยาก หวังว่าจะได้ยินไปถึงผู้หลักผู้ใหญ่ในบ้านเมืองบ้าง\n",
      "87 เห็นด้วยกับหมอ วันก่อนยังคำนวนว่าควรปรับวันเปิดเทอม ปิดเทอม ฝุ่นเข้มข้นสูง เด็กต้องหายใจเข้าอีกนาน ว่าที่กำลังสำคัญของชาติทั้งนั้นนะ สะสมฝุ่นแต่น้อย คิดดูส่งผลกระทบต่อร่างกายและจิตขนาดไหน\n",
      "93 เมื่อวานท่านโฆษกยังบอกว่าระดับPM2.5 ตอนนี้น้อย เพราะเรามานั่งพูดกลางแจ้งได้ และอย่าเชื่อแอพที่วิเคราะห์ค่าระดับฝุ่นละอองมาก ให้เชื่อรัฐบาล.... เอิ่มมม WTF\n",
      "96 หวังไว้ว่าอนาคตเราคงไม่ต้องจ่ายเงินเพื่อซื้ออากาศบริสุทธิ์หายใจ ขอให้เป็นเพียงเรื่องในหนังและจินตนาการเท่านั้นเถอะ 🙏\n",
      "106 เผาหญ้า ข้างทางด้วยล่าสุด วงแหวนรอบนอก ยังไม่มีใครไปดับถ้าเป็นงี้ต่อไป คงตายกันหมดhttps//pbs.twimg.com/media/DxfiJaPVYAAhGvJ.jpg\n",
      "110 แต่เรามีปัญญาจัดข้าวเหนียวมะม่วงยักษ์เลี้ยงนักท่องเที่ยวนะคะ  เรามาถึงจุดนี้กันแล้ว\n",
      "113 ให้ลูกหยุดเองคือทางออกของมนุษย์แม่ค่ะ เศร้าาาา\n",
      "115 AQI criteria ของกรมควบคุมมลพิษก็ไม่ได้ใช้เกณฑ์เดี๋ยวกันกับของ WHO ที่แบ่งละเอียดกว่าอีกด้วย\n",
      "116 เราไม่รู้ว่าอาเซียนปิดเทอมช่วงไหน แต่เราเห็นหลายประเทศ ปิดเทอมเล็กช่วงต้นมกรา(มาเล และโซนอาหรับ หลายประเทศ)\n",
      "128 ต่อไป กรุงเทพ จะไม่ใช่เมืองน่าอยู่แล้ว คุณภาพชีวิตลดลง\n",
      "136 นั่นสิคะ ไม่เห็นทำไร ยังปล่อยผ่านทุกวัน เห็นแต่เร่งหาเสียง หาไปไม่รู้ใครจะเลือก อนาถ\n",
      "138 กทมสั่งปิดรร ชั่วคราว.นะคะ\n",
      "139 ปัญหานี้ต้องใช้ความ “กล้าหาญ” ในการตัดสินใจครับ\n",
      "140 จริงค่ะ นี่สั่งลูกให้ใส่ตลอดเวลาอยู่กลางแจ้งที่รร.ไหนวันนี้มีวิชาพละอีก\n",
      "145 เสนอ ประกาศเป็นวันหยุดกรณีพิเศษ เฉพาะ รร และราชการ 3วัน  เฉพาะกรุงเทพ และปริมณฑลค่ะ น่าจะช่วยได้เยอะ\n",
      "146 เค้าอยากให้ดู.. ของจีน อันนี้มี sub eng 8 ตอนhttps//youtu.be/MhIZ50HKIp0\n",
      "157 ช่วยกันแชร์จะได้เป็นวงกว้าง​ เด็กที่บ้านก็หยุดอยู่บ้านละ\n",
      "162 สอบถามหน่อยคะทะเลบางแสนมีประผลกระทบเกี่ยวกับฝุ่นละอองรึป่าวคะจะพาลูกไปเที่ยวเลยขอข้อมูลหน่อยคะ🙏\n",
      "165 เห็นด้วยอย่างยิ่งค่ะ อธิบดีกรมควบคุมมลพิษยังบอกไม่วิกฤติเลย\n",
      "170 ระหว่างนี้ถ้าใครสามารถผลิตเครื่องกรองอากาศชนิดพกพาราคาย่อมเยาว์ได้น่าจะรวยกระทันหัน\n",
      "174 จะถึงหูเค้าไหม. วันนี้ฟังผู้ใหญ่ใน กทม ให้สัมภาษณ์แล้วยังถอนใจ.\n",
      "176 จริงๆคิดว่าจะได้เห็นภาพรัฐอัดฉีดงบหน้ากากมาแจกซะอีกแต่กลายเป็นว่าเงียบกริบ\n",
      "177 ทีรร.ลูกยังให้เด็กเข้าแถวหน้าเสาธงตามปกติอยู่เลยค่ะ อดเป็นห่วงเด็กๆไม่ได้เลย\n",
      "178 น่าแก้ไข เอาเป็นนโยบาย วาระแห่งชาติเลย\n",
      "179 คุยกับเสาไฟฟ้า ได้ อะไรมากกว่า\n",
      "182 ร่วมแชร์นะคะ\n",
      "188 😁 ขออนุญาตแชร์นะครับคุณหมอ🙏🙏\n",
      "189 ใกล้เลือกตั้งเกรงใจปชช.มาก\n",
      "191 อยุ่ลาดพร้าว55ค่ะ\n",
      "192 จริงๆ ทำไม ไม่จริงจัง 😷\n",
      "194 ขออนุญาตแชร์นะคะ\n",
      "195 สิงคโปร์ปลูกใบพลูง่ายๆนี่แหละดูดฝุ่น\n",
      "196 อยากให้รร หยุดจริงๆนะคะ\n",
      "197 จริงมากค่ะ ทำไมรัฐดูเอื่อยๆเฉื่อยๆ\n",
      "198 เช้านี้พอเปิดหน้าต่าง .นำ้มูกน้ำตาไหลพรากเลยค่ะ\n",
      "202 ขออนุญาตแชร์ค่ะ\n",
      "204 เชียงใหม่เป็นมา 10 ปี ละครับ ยังแก้ไม่ได้เลย\n",
      "205 ขอshare นะจ๊ะ ตรงใจมาก\n",
      "208 ลูกสาวป่วยเลยคะ น่ากลัวมากๆ\n",
      "211 ขออนุญาตแชร์ค่ะคุณหมอ\n",
      "213 นั่นแหละวิสัยทัศน์  เลือกตั้งก็คิดกันเยอะๆหน่อยละกัน\n",
      "216 ใช่เลยครับ\n",
      "217 ยุทธศาสตร์ผังเมือง20ปีก่อน ผิดพลาด ไปมากค่ะ\n",
      "219 เข้า กทม.2วันแสบคอสุดๆ ป่วยค่ะ\n",
      "220 +1\n",
      "221 ต้องดูแล ตัวเอง ตามที่นายกตู่ว่าไว้นะ\n",
      "222 เห็นด้วย​อย่างมาก\n",
      "227 https//www.posttoday.com/social/general/577217\n",
      "228 แล้วคือตลกมากเข้าแถวออกกำลังกาย พร้อมสูดอากาศพิษ หูยย..นะคะ\n"
     ]
    }
   ],
   "source": [
    "w1 = Widget(new_result, 'comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91b401f367841e69f9176ec301aec10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(options=(0, 1, 2, 3, 4, 5, 6, 7, 8), value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 หงุดหงิดมากอะ รร ลูกอยู่ตรงปทุมวัน เขตนี้ควันนรกมากเลยอะ ต้องพยายามให้ใส่หน้ากาก ไม่รู้จะช่วยได้แค่ไหน ให้ใส่แบบกันเยอะๆ นางก็บ่น แต่นางก็ใส่แหละ\n",
      "6 วันนี้เขตโรงเรียนลูก 249 รร.ไม่หยุด แม่หยุดเองเลยค่ะ\n",
      "15 ที่น่าสังเวคือยังมีคนจำนวนหนึ่งมองว่าพวกเราบ้าประสาทตื่นตูมกันอยู่เลย ใส่หน้ากากก็โดนมองเหมือนสัตว์ประหลาด\n",
      "17 T T ควรประกาศภัยพิบัติได้แล้วนะครับ  ผลกระทบต่อสุขภาพระยะยาวแบบเลี่ยงไม่ได้ สุดท้ายจะกลายเป็นภาระมหาศาลของระบบสาธารณสุขเลย\n",
      "22 ตอนนี้รัดทะบาน ห่วงแต่การสืบทอดอำนาจ สนจัยอะไรที่ไหนกัน ทนได้ก้อทนกันไป ทนไม่ได้ก้อทำอะไรไม่ได้ ประเทศไทย จะไม่มีคนดีๆ มาบริหารประเทศเลยหรอ\n",
      "34 นอกจากการหายใจ ตอนนี้เริ่มแสบตา ระคายเคืองตา  แล้วก็คันที่ผิวหนังบ่อยขึ้นค่ะ ไม่รู้เราคิดไปเองไหม แต่ปกติผิวหนังไม่เคยแพ้อะไรเลย\n",
      "41 นานๆจะเห็นหมอขึ้น ดูเหมือนนายกจะออกมาตราการ มา 9ข้อ แล้วนะครับ แต่อ่านๆดูบางข้อก็รู้สึกมันเป็นเรื่องที่ภาวะปกติก็ต้องทำอยู่แล้วรึเปล่า\n",
      "42 เชียงใหม่ ช่วงปลายกุมภา  ถึงกลางเมษาจะเลวร้ายมา 3 ปี  มีปีนึงที่รณรงค์   ช่วยกันเต็มที่ ลดลงได้บ้าง  แต่พอลดลง  บนป่าก็มาเผาเหมือนเดิม  เศร้าใจมากค่ะ\n",
      "50 ท่าทีของผู้ใหญ่ในบ้านเมืองยังดูอายที่จะประกาศว่าจริงๆมันวิกฤตแล้ว ยังคงพยายามสร้างภาพ ให้ข่าวว่ามันไม่ได้อันตรายขนาดนั้น ตัวเลข PM2.5 ของหน่วยงานรัฐ น้อยกว่าของเว็ปไซต์ที่เป็นที่ยอมรับในระดับสากลเยอะ 😓😓😓\n",
      "54 This shows everything about Thailand\n",
      "56 เห็นด้วยเป็นอย่างยิ่ง มีแต่พูดกันออกสื่อไม่เคยลงมาดูพื้นที่จริงๆ ว่าปัญหามันคืออะไร มาดูถนนกาญจนฯ จ.สมุทรสาครสิคะ ว่าปัญหามันคืออะไร ไม่ใช่นั่งเทียนพูดๆๆๆๆๆ ไป เหนื่อยใจค่ะ ย้อนกลับมาแก้ไขและป้องกันลูกๆเรา ด้วยตัวเราเองค่ะ -_-||\n",
      "63 เสนอเพิ่มว่าควรปิดเทอมหน้าฝน เพราะทั้งเด็กทั้งผู้ใหญ่เดินทางกันลำบากมาก เด็กก็ป่วยง่ายในช่วงนั้นค่ะ รัฐบาลควรคิดแก้ไขเพื่อเด็กๆบ้างก็ดี ถึงจะแก้อะไรไม่ค่อยได้เรื่อง\n",
      "67 ขออนุญาตค่ะด่วน!!!!!!!!!!!!!!!!!!!!หน้ากาก N95ป้องกันฝุ่นชนิด PM2.5 micronชนิดมีวาล์ป ทำให้หายใจไม่ลำบากมาก ร่วมกับมีคาร์บอนเคลือบ ช่วยในการกรองมากขึ้นราคาชิ้นละ 40 บาทค่าส่ง  ลงทะเบียน 30 บาท            EMS           50 บาท            รพ. รามา    ฟรี            หน้า รร สตรีนนท์ ฟรีหมดล็อตนี้หมดเลยสนใจ ib มาเลยค่ะ ของมาถึงวันจันทร์\n",
      "71 ข้อเสนอคุณหมอดีมากๆค่ะ เห็นด้วยทุกข้อและ implement ได้ไม่ยาก หวังว่าจะได้ยินไปถึงผู้หลักผู้ใหญ่ในบ้านเมืองบ้าง\n",
      "87 เห็นด้วยกับหมอ วันก่อนยังคำนวนว่าควรปรับวันเปิดเทอม ปิดเทอม ฝุ่นเข้มข้นสูง เด็กต้องหายใจเข้าอีกนาน ว่าที่กำลังสำคัญของชาติทั้งนั้นนะ สะสมฝุ่นแต่น้อย คิดดูส่งผลกระทบต่อร่างกายและจิตขนาดไหน\n",
      "93 เมื่อวานท่านโฆษกยังบอกว่าระดับPM2.5 ตอนนี้น้อย เพราะเรามานั่งพูดกลางแจ้งได้ และอย่าเชื่อแอพที่วิเคราะห์ค่าระดับฝุ่นละอองมาก ให้เชื่อรัฐบาล.... เอิ่มมม WTF\n",
      "96 หวังไว้ว่าอนาคตเราคงไม่ต้องจ่ายเงินเพื่อซื้ออากาศบริสุทธิ์หายใจ ขอให้เป็นเพียงเรื่องในหนังและจินตนาการเท่านั้นเถอะ 🙏\n",
      "106 เผาหญ้า ข้างทางด้วยล่าสุด วงแหวนรอบนอก ยังไม่มีใครไปดับถ้าเป็นงี้ต่อไป คงตายกันหมดhttps//pbs.twimg.com/media/DxfiJaPVYAAhGvJ.jpg\n",
      "110 แต่เรามีปัญญาจัดข้าวเหนียวมะม่วงยักษ์เลี้ยงนักท่องเที่ยวนะคะ  เรามาถึงจุดนี้กันแล้ว\n",
      "113 ให้ลูกหยุดเองคือทางออกของมนุษย์แม่ค่ะ เศร้าาาา\n",
      "115 AQI criteria ของกรมควบคุมมลพิษก็ไม่ได้ใช้เกณฑ์เดี๋ยวกันกับของ WHO ที่แบ่งละเอียดกว่าอีกด้วย\n",
      "116 เราไม่รู้ว่าอาเซียนปิดเทอมช่วงไหน แต่เราเห็นหลายประเทศ ปิดเทอมเล็กช่วงต้นมกรา(มาเล และโซนอาหรับ หลายประเทศ)\n",
      "128 ต่อไป กรุงเทพ จะไม่ใช่เมืองน่าอยู่แล้ว คุณภาพชีวิตลดลง\n",
      "136 นั่นสิคะ ไม่เห็นทำไร ยังปล่อยผ่านทุกวัน เห็นแต่เร่งหาเสียง หาไปไม่รู้ใครจะเลือก อนาถ\n",
      "138 กทมสั่งปิดรร ชั่วคราว.นะคะ\n",
      "139 ปัญหานี้ต้องใช้ความ “กล้าหาญ” ในการตัดสินใจครับ\n",
      "140 จริงค่ะ นี่สั่งลูกให้ใส่ตลอดเวลาอยู่กลางแจ้งที่รร.ไหนวันนี้มีวิชาพละอีก\n",
      "145 เสนอ ประกาศเป็นวันหยุดกรณีพิเศษ เฉพาะ รร และราชการ 3วัน  เฉพาะกรุงเทพ และปริมณฑลค่ะ น่าจะช่วยได้เยอะ\n",
      "146 เค้าอยากให้ดู.. ของจีน อันนี้มี sub eng 8 ตอนhttps//youtu.be/MhIZ50HKIp0\n",
      "157 ช่วยกันแชร์จะได้เป็นวงกว้าง​ เด็กที่บ้านก็หยุดอยู่บ้านละ\n",
      "162 สอบถามหน่อยคะทะเลบางแสนมีประผลกระทบเกี่ยวกับฝุ่นละอองรึป่าวคะจะพาลูกไปเที่ยวเลยขอข้อมูลหน่อยคะ🙏\n",
      "165 เห็นด้วยอย่างยิ่งค่ะ อธิบดีกรมควบคุมมลพิษยังบอกไม่วิกฤติเลย\n",
      "170 ระหว่างนี้ถ้าใครสามารถผลิตเครื่องกรองอากาศชนิดพกพาราคาย่อมเยาว์ได้น่าจะรวยกระทันหัน\n",
      "174 จะถึงหูเค้าไหม. วันนี้ฟังผู้ใหญ่ใน กทม ให้สัมภาษณ์แล้วยังถอนใจ.\n",
      "176 จริงๆคิดว่าจะได้เห็นภาพรัฐอัดฉีดงบหน้ากากมาแจกซะอีกแต่กลายเป็นว่าเงียบกริบ\n",
      "177 ทีรร.ลูกยังให้เด็กเข้าแถวหน้าเสาธงตามปกติอยู่เลยค่ะ อดเป็นห่วงเด็กๆไม่ได้เลย\n",
      "178 น่าแก้ไข เอาเป็นนโยบาย วาระแห่งชาติเลย\n",
      "179 คุยกับเสาไฟฟ้า ได้ อะไรมากกว่า\n",
      "182 ร่วมแชร์นะคะ\n",
      "188 😁 ขออนุญาตแชร์นะครับคุณหมอ🙏🙏\n",
      "189 ใกล้เลือกตั้งเกรงใจปชช.มาก\n",
      "191 อยุ่ลาดพร้าว55ค่ะ\n",
      "192 จริงๆ ทำไม ไม่จริงจัง 😷\n",
      "194 ขออนุญาตแชร์นะคะ\n",
      "195 สิงคโปร์ปลูกใบพลูง่ายๆนี่แหละดูดฝุ่น\n",
      "196 อยากให้รร หยุดจริงๆนะคะ\n",
      "197 จริงมากค่ะ ทำไมรัฐดูเอื่อยๆเฉื่อยๆ\n",
      "198 เช้านี้พอเปิดหน้าต่าง .นำ้มูกน้ำตาไหลพรากเลยค่ะ\n",
      "202 ขออนุญาตแชร์ค่ะ\n",
      "204 เชียงใหม่เป็นมา 10 ปี ละครับ ยังแก้ไม่ได้เลย\n",
      "205 ขอshare นะจ๊ะ ตรงใจมาก\n",
      "208 ลูกสาวป่วยเลยคะ น่ากลัวมากๆ\n",
      "211 ขออนุญาตแชร์ค่ะคุณหมอ\n",
      "213 นั่นแหละวิสัยทัศน์  เลือกตั้งก็คิดกันเยอะๆหน่อยละกัน\n",
      "216 ใช่เลยครับ\n",
      "217 ยุทธศาสตร์ผังเมือง20ปีก่อน ผิดพลาด ไปมากค่ะ\n",
      "219 เข้า กทม.2วันแสบคอสุดๆ ป่วยค่ะ\n",
      "220 +1\n",
      "221 ต้องดูแล ตัวเอง ตามที่นายกตู่ว่าไว้นะ\n",
      "222 เห็นด้วย​อย่างมาก\n",
      "227 https//www.posttoday.com/social/general/577217\n",
      "228 แล้วคือตลกมากเข้าแถวออกกำลังกาย พร้อมสูดอากาศพิษ หูยย..นะคะ\n"
     ]
    }
   ],
   "source": [
    "w2 = Widget(result, 'comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65158f0206a649949b8e162dd32ea2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(options=(0, 1, 2, 3, 4, 5, 6, 7, 8), value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ['ลูก', 'หน้า', 'ใส่', 'ใส่', 'ใส่', 'รู้', 'กาก', 'รร', 'ควัน', 'เขต']\n",
      "6 ['หยุด', 'หยุด', 'โรง', 'รร', 'แม่', 'เขต']\n",
      "15 ['คน', 'หน้า', 'ใส่', 'เหมือน', 'กาก', 'ตื่น', 'โดน', 'ประหลาด', 'จำนวน', 'บ้า', 'ตูม']\n",
      "17 ['ประกาศ', 'สุขภาพ', 'กลาย', 'ระบบ', 'กระทบ', 'สุดท้าย', 'ภัยพิบัติ', 'เลี่ยง', 'ภาระ', 'สาธารณสุข']\n",
      "22 ['ทำ', 'คน', 'ดี', 'ตอน', 'ประเทศ', 'อำนาจ', 'ทน', 'ทน', 'ทน', 'ประเทศไทย', 'บริหาร', 'หรอ', 'ห่วง', 'ก้อ', 'ก้อ']\n",
      "34 ['ตอน', 'รู้', 'หายใจ', 'ไหม', 'ตา', 'ตา', 'ปกติ', 'คัน', 'แสบ', 'แพ้', 'ระคายเคือง']\n",
      "41 ['ทำ', 'หมอ', 'เรื่อง', 'ดู', 'เหมือน', 'ดู', 'ปกติ', 'ข้อ', 'ข้อ', 'นายก', 'อ่าน', 'รู้สึก', 'อยู่แล้ว', 'ภาวะ', 'มาตราการ']\n",
      "42 ['เหมือน', 'ปี', 'ปี', 'ลด', 'ลด', 'กลาง', 'นึง', 'รณรงค์', 'เผา', 'เดิม', 'เชียงใหม่', 'เศร้าใจ', 'ป่า']\n",
      "50 ['ตัว', 'งาน', 'ดู', 'รัฐ', 'ประกาศ', 'ข่าว', 'ขนาด', 'อันตราย', 'วิกฤต', 'สร้าง', 'บ้านเมือง', 'ภาพ', 'หน่วย', 'ระดับ', 'อาย']\n",
      "54 []\n",
      "56 ['ตัว', 'ลูก', 'ปัญหา', 'ปัญหา', 'ดู', 'นั่ง', 'ป้องกัน', 'พื้นที่', 'สิ']\n",
      "63 ['เด็ก', 'เด็ก', 'เด็ก', 'เรื่อง', 'รัฐบาล', 'หน้า', 'แก้', 'ป่วย', 'เสนอ', 'ลำบาก', 'เทอม', 'เดินทาง', 'ฝน']\n",
      "67 ['ทำ', 'ฝุ่น', 'หน้า', 'หน้า', 'กาก', 'หายใจ', 'ป้องกัน', 'ค่า', 'อนุญาต', 'ลำบาก', 'กรอง', 'ทะเบียน', 'สนใจ', 'ราคา', 'บาท']\n",
      "71 ['หวัง', 'ข้อ', 'เสนอ', 'ข้อ', 'บ้านเมือง', 'ผู้หลักผู้ใหญ่']\n",
      "87 ['หมอ', 'เด็ก', 'ฝุ่น', 'ฝุ่น', 'ดู', 'หายใจ', 'ขนาด', 'ชาติ', 'กระทบ', 'เทอม', 'เทอม', 'สะสม', 'ร่างกาย', 'จิต']\n",
      "93 ['ฝุ่น', 'รัฐบาล', 'ตอน', 'กลาง', 'นั่ง', 'แจ้ง', 'ค่า', 'ท่าน', 'อย่า', 'วาน', 'ระดับ', 'ระดับ', 'ละออง', 'วิเคราะห์']\n",
      "96 ['เรื่อง', 'อากาศ', 'ซื้อ', 'หายใจ', 'หวัง', 'อนาคต', 'เงิน', 'จ่าย']\n",
      "106 ['เผา', 'ตาย', 'หญ้า', 'รอบ', 'ดับ']\n",
      "110 ['จุด', 'เลี้ยง', 'ท่องเที่ยว']\n",
      "113 ['ลูก', 'หยุด', 'แม่', 'มนุษย์']\n",
      "115 ['กรมควบคุมมลพิษ', 'เดี๋ยว', 'เกณฑ์', 'แบ่ง']\n",
      "116 ['รู้', 'ต้น', 'ประเทศ', 'ประเทศ', 'เทอม', 'เทอม', 'อาเซียน']\n",
      "128 ['ลด', 'ชีวิต', 'กรุงเทพ', 'คุณภาพ', 'อยู่แล้ว']\n",
      "136 ['รู้', 'หา', 'ปล่อย', 'เร่ง', 'สิ', 'เลือก', 'หาเสียง']\n",
      "138 ['รร', 'สั่ง', 'กทม', 'ชั่วคราว']\n",
      "139 ['ปัญหา', 'ตัดสินใจ']\n",
      "140 ['ลูก', 'ใส่', 'รร', 'กลาง', 'แจ้ง', 'สั่ง', 'เวลา', 'วิชา', 'พละ']\n",
      "145 ['หยุด', 'รร', 'ประกาศ', 'เสนอ', 'ราชการ', 'กรุงเทพ', 'กรณี']\n",
      "146 ['ตอน', 'ดู', 'เค้า', 'จีน']\n",
      "157 ['เด็ก', 'บ้าน', 'บ้าน', 'หยุด', 'แชร์']\n",
      "162 ['ฝุ่น', 'ลูก', 'กระทบ', 'เกี่ยว', 'เที่ยว', 'ข้อมูล', 'แสน', 'ละออง']\n",
      "165 ['กรมควบคุมมลพิษ', 'วิกฤติ', 'อธิบดี']\n",
      "170 ['อากาศ', 'เครื่อง', 'กรอง', 'ผลิต', 'ชนิด', 'รวย']\n",
      "174 ['ไหม', 'กทม', 'เค้า', 'ฟัง', 'หู']\n",
      "176 ['รัฐ', 'หน้ากาก', 'กลาย', 'ภาพ', 'แจก', 'ฉีด', 'งบ']\n",
      "177 ['เด็ก', 'เด็ก', 'ลูก', 'หน้า', 'แถว', 'ปกติ', 'เสา', 'เป็นห่วง', 'ธง']\n",
      "178 ['นโยบาย', 'ชาติ']\n",
      "179 ['ไฟฟ้า', 'คุย', 'เสา']\n",
      "182 ['แชร์']\n",
      "188 ['แชร์', 'อนุญาต', 'คุณหมอ']\n",
      "189 ['เลือกตั้ง', 'ปชช']\n",
      "191 []\n",
      "192 []\n",
      "194 ['แชร์', 'อนุญาต']\n",
      "195 ['ฝุ่น', 'ปลูก', 'ใบ', 'สิงคโปร์', 'พลู', 'ดูด']\n",
      "196 ['หยุด', 'รร']\n",
      "197 ['ดู', 'รัฐ']\n",
      "198 ['เช้า', 'ตา', 'น้ำ', 'หน้าต่าง', 'มูก', 'ไหล']\n",
      "202 ['แชร์', 'อนุญาต']\n",
      "204 ['ปี', 'แก้', 'เชียงใหม่']\n",
      "205 []\n",
      "208 ['ลูก', 'ป่วย', 'กลัว', 'สาว']\n",
      "211 ['แชร์', 'อนุญาต', 'คุณหมอ']\n",
      "213 ['เลือกตั้ง', 'วิสัยทัศน์']\n",
      "216 []\n",
      "217 ['ปี', 'เมือง']\n",
      "219 ['ป่วย', 'แสบ', 'คอ']\n",
      "220 []\n",
      "221 ['ตัว', 'ดูแล', 'นายก']\n",
      "222 []\n",
      "227 []\n",
      "228 ['อากาศ', 'แถว', 'พิษ', 'สูด', 'ตลก']\n"
     ]
    }
   ],
   "source": [
    "w3 = Widget(result, 'tokenized_comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "['ประกาศ', 'หยุด', 'เรียน', 'ระดับ', 'ชั้น', 'บริหาร', 'โรง', 'เรียน', 'ประกาศ', 'ชม']\n",
      "รร.รุ่งอรุณประกาศหยุดเรียนทุกระดับชั้น ชื่นชมผู้บริหารโรงเรียนในการตัดสิ้นใจค่ะ ประกาศเมื่อราว 1 ชม.ที่ผ่านมาค่ะ\n",
      "['ประกาศ', 'หยุด', 'เรียน', 'ระดับ', 'ชั้น', 'บริหาร', 'โรง', 'เรียน', 'ประกาศ', 'ชม']\n",
      "รร.รุ่งอรุณประกาศหยุดเรียนทุกระดับชั้น ชื่นชมผู้บริหารโรงเรียนในการตัดสิ้นใจค่ะ ประกาศเมื่อราว 1 ชม.ที่ผ่านมาค่ะ\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "compare = 0\n",
    "\n",
    "a = numpy.array(onehot_corpus.iloc[seed]).reshape(1, -1)\n",
    "b = numpy.array(onehot_corpus.iloc[compare]).reshape(1, -1)\n",
    "print(cosine_similarity(a,b))\n",
    "\n",
    "print(idx_corpus[seed])\n",
    "print(corpus[seed])\n",
    "print(idx_corpus[compare])\n",
    "print(corpus[compare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senior-project",
   "language": "python",
   "name": "senior-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
