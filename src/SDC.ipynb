{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "import pythainlp\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from data_tokenizer import load_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents 269\n",
      "1 clusters\n"
     ]
    }
   ],
   "source": [
    "file_name = 'ผู้บริโภค - TescoLotus.txt'\n",
    "\n",
    "corpus, labels = load_corpus('../data/facebook/' + file_name)\n",
    "\n",
    "len_corpus = len(corpus)\n",
    "print('Total documents', len_corpus)\n",
    "\n",
    "clusters = list(set(labels))\n",
    "print(len(clusters), 'clusters')\n",
    "\n",
    "f = open('../data/facebook/tokenized/tokenized_' + file_name)\n",
    "tokenized_corpus = eval(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: 1313 words\n",
      "filter frequent words: 540 words\n",
      "filter letter words: 539 words\n",
      "filter stop words: 352 words\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(tokenized_corpus)\n",
    "print('origin:', len(dictionary), 'words')\n",
    "\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.7, keep_n=len(dictionary))\n",
    "print('filter frequent words:', len(dictionary), 'words')\n",
    "\n",
    "letter_words = [id for id in range(len(dictionary)) if len(dictionary[id]) <= 1] \n",
    "dictionary.filter_tokens(bad_ids=letter_words)\n",
    "print('filter letter words:', len(dictionary), 'words')\n",
    "\n",
    "stopwords = pythainlp.corpus.stopwords.words('thai')\n",
    "stopwords.append('นี้')\n",
    "dictionary.add_documents([stopwords])\n",
    "stopwords = [dictionary.token2id[word] for word in stopwords]\n",
    "dictionary.filter_tokens(bad_ids=stopwords)\n",
    "print('filter stop words:', len(dictionary), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_corpus]\n",
    "idx_corpus = [dictionary.doc2idx(doc) for doc in tokenized_corpus]\n",
    "\n",
    "temp_corpus = []\n",
    "for doc in idx_corpus:\n",
    "    temp_corpus.append([dictionary[id] for id in doc if id >= 0])\n",
    "idx_corpus = temp_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_doc_size = 0\n",
    "for doc in idx_corpus:\n",
    "    average_doc_size += len(doc)\n",
    "average_doc_size /= len(idx_corpus)\n",
    "average_doc_size = math.ceil(average_doc_size)\n",
    "\n",
    "df = dictionary.dfs\n",
    "filtered_corpus = []\n",
    "for doc in idx_corpus:\n",
    "    new_doc = [(word, df[dictionary.token2id[word]]) for word in doc]\n",
    "    new_doc.sort(reverse=True, key=lambda x: x[1])\n",
    "    new_doc = new_doc[:average_doc_size]\n",
    "    filtered_corpus.append([word for word, df in new_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow(corpus):\n",
    "    new_dict = Dictionary(corpus)\n",
    "\n",
    "    # new_dict.filter_extremes(no_below=2, no_above=1, keep_n=len(new_dict))\n",
    "    # print(len(new_dict))\n",
    "\n",
    "    unique_words = [new_dict[id] for id in range(len(new_dict))]\n",
    "    array = numpy.zeros((len_corpus, len(unique_words)), dtype=float)\n",
    "    \n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc:\n",
    "            array[i, new_dict.token2id[word]] += 1\n",
    "\n",
    "        ## normalization\n",
    "        if len(doc) != 0:\n",
    "            array[i] = numpy.divide(array[i], len(idx_corpus[i]))\n",
    "\n",
    "    return pandas.DataFrame(array, columns=unique_words, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdc(bow_corpus, min_samples, eps):\n",
    "    delta_eps = eps / 10\n",
    "    labels = [-1 for i in range(len(bow_corpus))]\n",
    "    sims = cosine_similarity(bow_corpus)\n",
    "    \n",
    "    points = [i for i in range(len(bow_corpus))]\n",
    "    cluster_num = 0\n",
    "    while len(points) > 0:\n",
    "        seed = random.choice(points)\n",
    "        eps_neighbors = [i for i, sim in enumerate(sims[seed]) if sim >= eps and labels[i] == -1]\n",
    "        if len(eps_neighbors) >= min_samples:\n",
    "            cluster_num += 1\n",
    "            for p in eps_neighbors:\n",
    "                labels[p] = cluster_num\n",
    "            points = [i for i in points if i not in eps_neighbors]\n",
    "        else:\n",
    "            labels[seed] = 0\n",
    "            points.remove(seed)\n",
    "\n",
    "    while cluster_num != 0:\n",
    "        cluster = [numpy.array(bow_corpus.iloc[i]) for i, label in enumerate(labels) if label == cluster_num]\n",
    "        eps_temp = eps\n",
    "        \n",
    "        while True:\n",
    "            centroid = numpy.mean(cluster, axis=0).reshape(1, -1)\n",
    "            eps_temp -= delta_eps\n",
    "            \n",
    "            count = 0\n",
    "            for i, label in enumerate(labels):\n",
    "                point = numpy.array(bow_corpus.iloc[i]).reshape(1, -1)\n",
    "                if label == 0 and cosine_similarity(centroid, point) >= eps_temp:\n",
    "                    cluster.append(point[0])\n",
    "                    labels[i] = cluster_num\n",
    "                    count += 1\n",
    "            if count == 0:\n",
    "                break\n",
    "        \n",
    "        cluster_num -= 1\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upgrade_sdc(bow_corpus, min_samples, eps):\n",
    "    labels = [-1 for i in range(len(bow_corpus))]\n",
    "    initials = []\n",
    "    delta_eps = eps / 20\n",
    "    sims = cosine_similarity(bow_corpus)\n",
    "    \n",
    "    points = [i for i in range(len(bow_corpus))]\n",
    "    clusters = []\n",
    "    cluster_num = 0\n",
    "    clusters.append([])\n",
    "    while len(points) > 0:\n",
    "        seed = random.choice(points)\n",
    "        eps_neighbors = [i for i, sim in enumerate(sims[seed]) if sim >= eps and labels[i] == -1]\n",
    "        if len(eps_neighbors) >= min_samples:\n",
    "            print(seed)\n",
    "            cluster_num += 1\n",
    "            clusters.append([])\n",
    "            for p in eps_neighbors:\n",
    "                initials.append(p)\n",
    "                labels[p] = cluster_num\n",
    "                clusters[cluster_num].append(numpy.array(bow_corpus.iloc[p]))\n",
    "            points = [i for i in points if i not in eps_neighbors]\n",
    "        else:\n",
    "            labels[seed] = 0\n",
    "            clusters[0].append((seed, numpy.array(bow_corpus.iloc[seed])))\n",
    "            points.remove(seed)\n",
    "            \n",
    "    expandable = numpy.zeros(cluster_num + 1)    \n",
    "    while numpy.sum(expandable) != -cluster_num - 1:\n",
    "        eps -= delta_eps\n",
    "        count = numpy.zeros(cluster_num + 1)\n",
    "        for point in clusters[0]:\n",
    "            if labels[point[0]] != 0:\n",
    "                continue\n",
    "\n",
    "            num = point[0]\n",
    "            p = point[1].reshape(1, -1)\n",
    "            sim = 0\n",
    "            for c, cluster in enumerate(clusters[1:]):\n",
    "                if expandable[c + 1] == -1:\n",
    "                    continue\n",
    "                centroid = numpy.mean(cluster, axis=0).reshape(1, -1)\n",
    "                if cosine_similarity(centroid, p) >= sim:\n",
    "                    sim = cosine_similarity(centroid, p)\n",
    "                    if sim >= eps:\n",
    "                        labels[num] = c + 1\n",
    "\n",
    "            if labels[num] != 0:\n",
    "                count[labels[num]] += 1\n",
    "                clusters[labels[num]].append(point[1])\n",
    "\n",
    "        for i, num in enumerate(count):\n",
    "            if num == 0:\n",
    "                expandable[i] = -1\n",
    "        \n",
    "    return labels, initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster(bow_corpus, min_samples, eps):\n",
    "    predicted_labels, initials = upgrade_sdc(bow_corpus, min_samples, eps)\n",
    "\n",
    "    result = pandas.DataFrame()\n",
    "    result['comment'] = corpus\n",
    "    result['tokenized_comment'] = filtered_corpus\n",
    "    result['label'] = labels\n",
    "    result['predicted_label'] = predicted_labels\n",
    "    \n",
    "    return result, initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "200\n",
      "165\n",
      "90\n",
      "145\n",
      "186\n",
      "265\n",
      "61\n",
      "249\n",
      "199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ทำ</th>\n",
       "      <th>พนักงาน</th>\n",
       "      <th>ข้าว</th>\n",
       "      <th>ดี</th>\n",
       "      <th>น้ำ</th>\n",
       "      <th>อี</th>\n",
       "      <th>เครื่อง</th>\n",
       "      <th>เลิก</th>\n",
       "      <th>กก</th>\n",
       "      <th>งง</th>\n",
       "      <th>...</th>\n",
       "      <th>พลังงาน</th>\n",
       "      <th>คอย</th>\n",
       "      <th>แอร์ไม่</th>\n",
       "      <th>สลิป</th>\n",
       "      <th>คู</th>\n",
       "      <th>ปอง</th>\n",
       "      <th>นวมินทร์</th>\n",
       "      <th>สิบ</th>\n",
       "      <th>ห้า</th>\n",
       "      <th>แจก</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ทำ   พนักงาน      ข้าว        ดี       น้ำ        อี   เครื่อง  \\\n",
       "0  0.107143  0.214286  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.166667  0.166667  0.166667  0.166667  0.166667   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.083333  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.100000  0.100000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       เลิก        กก        งง ...   พลังงาน  คอย  แอร์ไม่  สลิป   คู  ปอง  \\\n",
       "0  0.000000  0.000000  0.000000 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "1  0.166667  0.000000  0.000000 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "2  0.000000  0.083333  0.083333 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "3  0.000000  0.000000  0.000000 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "4  0.000000  0.000000  0.000000 ...       0.0  0.0      0.0   0.0  0.0  0.0   \n",
       "\n",
       "   นวมินทร์  สิบ  ห้า  แจก  \n",
       "0       0.0  0.0  0.0  0.0  \n",
       "1       0.0  0.0  0.0  0.0  \n",
       "2       0.0  0.0  0.0  0.0  \n",
       "3       0.0  0.0  0.0  0.0  \n",
       "4       0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bow_corpus = get_bow(idx_corpus)\n",
    "bow_corpus = get_bow(filtered_corpus)\n",
    "result, initials = predict_cluster(bow_corpus, 7, 0.3)\n",
    "bow_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), array([62, 40, 21,  7, 25, 11, 17, 24, 32, 10, 20]))\n",
      "\t\tpercent\n",
      "0  |\t62\t1.0\n"
     ]
    }
   ],
   "source": [
    "label_count = numpy.unique(result['predicted_label'], return_counts=True) \n",
    "num_cluster = label_count[0][-1] + 1\n",
    "print(label_count)\n",
    "\n",
    "clusters = list(set(labels))\n",
    "for cluster in clusters:\n",
    "    print('\\t' + cluster, end='')\n",
    "print('\\tpercent')\n",
    "\n",
    "for label in range(len(clusters)):\n",
    "    print(str(label) + '  |', end='')\n",
    "    \n",
    "    num_max = 0\n",
    "    for cluster in clusters:\n",
    "        loc = result[(result['label'] == cluster) & (result['predicted_label'] == label)]\n",
    "        if len(loc) > num_max:\n",
    "            num_max = len(loc)\n",
    "        print('\\t' + str(len(loc)), end='')\n",
    "    \n",
    "    print('\\t' + str(num_max / label_count[1][label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIntra cluster sim\tInter cluster sim\tIntra / Inter\n",
      "0\t0.1927268415244628\t0.45232098530960013\t0.4260842361592997\n",
      "\n",
      "1\t0.5265292087288523\t0.7825697916030407\t0.6728207686758433\n",
      "\n",
      "2\t0.5663840662710057\t0.8143776719316573\t0.6954808386722773\n",
      "\n",
      "3\t0.7007641363850674\t0.4523297542535204\t1.5492328987765533\n",
      "\n",
      "4\t0.47615291555380196\t0.6032485154796914\t0.7893146909365778\n",
      "\n",
      "5\t0.5504883360177542\t0.45738484787747485\t1.2035561269078596\n",
      "\n",
      "6\t0.5515152818730108\t0.34241113208223495\t1.6106815176223783\n",
      "\n",
      "7\t0.6594282784325678\t0.39495077767928427\t1.6696467400503507\n",
      "\n",
      "8\t0.5262946635906929\t0.6867306310075376\t0.7663771496817304\n",
      "\n",
      "9\t0.6465301765561475\t0.19025997686112914\t3.3981407294506836\n",
      "\n",
      "10\t0.4578484322628202\t0.33211323688599864\t1.378591339977158\n",
      "\n",
      "Summation 125.43457957504059\n"
     ]
    }
   ],
   "source": [
    "clusters = [[] for i in range(num_cluster)]\n",
    "corpus_centroid = []\n",
    "for i, label in result['predicted_label'].iteritems():\n",
    "    clusters[label].append(numpy.array(bow_corpus.iloc[i]))\n",
    "    corpus_centroid.append(numpy.array(bow_corpus.iloc[i]))\n",
    "corpus_centroid = numpy.mean(corpus_centroid, axis=0).reshape(1, -1)   \n",
    "\n",
    "print('\\tIntra cluster sim\\tInter cluster sim\\tIntra / Inter')\n",
    "summation = 0\n",
    "for i in range(num_cluster):\n",
    "    size = len(clusters[i])\n",
    "    if size != 0:\n",
    "        print(i, end='\\t')\n",
    "        centroid = numpy.mean(clusters[i], axis=0).reshape(1, -1)\n",
    "        similarities = cosine_similarity(centroid, clusters[i])\n",
    "        pairwises = cosine_similarity(clusters[i])\n",
    "        intra = numpy.sum(similarities) / size\n",
    "        inter = cosine_similarity(centroid, corpus_centroid)[0][0]\n",
    "        print(intra, end='\\t')\n",
    "        print(inter, end='\\t')\n",
    "        print(intra / inter)\n",
    "        summation += numpy.sum(similarities)\n",
    "    print()\n",
    "print('Summation', summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d846eb675e064cf1990d2fa2606cd09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 เลิกเปิดเพลง ข้าวแสนดี กับอีเครื่องกรองน้ำเพียว ได้แล้ว\n",
      "5 อย่าบังคับน้องเข้าประชุมเชียร์ อย่าลงโทษโดยเหตุผลงี่เง่าๆ เกิดก่อนไม่กี่ปีเอง\n",
      "10 เค้าเตอร์มีเกือบ100ช่อง เปิดให้จ่ายตังไม่ถึง10ช่อง พี่ทำไว้โก้ๆหรอ ต่อคิวจ่ายตังกันไปดิ 10กว่านาที\n",
      "14 เทสโก้โลตัสสาขาบางกะปิทีวีตัวนี้อยู่บริเวณหน้าร้าน   ชั้นลอยชั้นเดียวกับไปรษณีย์ใกล้ประตูออกลานจอดรถ\n",
      "18 ช่องจ่ายเยอะ แต่เปิดไม่กี่ช่อง  คิวยาวไป เพลียยยยยพระราม 3  เลยค่ะ\n",
      "20 เช็คเอาท์  หน้าจะงอไปไหนสวัสดีค่ะมีอะไรให้ช่วยมั้ยคะ\n",
      "26 โลตลาด พนงปากตลาด นินทาลคเผาขน ตะโกนโหวกเหวกข้ามหัวลค วันหวยออกสนั่นเป็นพิเศษ เห็นพฤติกรรมแล้วแย่ ปรับปรุงภาพลักษณ์เถอะ\n",
      "29 ไม่ต้องตัดแต้มเป็นคูปองเงินได้ไหมอ่ะ ไม่เคยได้ใช้เพราะ คูปองมันหายก่อน เอาแบบ พอไปซื้อแล้วแต้มครบค่อยถามว่าตัดแต้มไหมคะ อะไรแบบนี้จะดีกว่า  แล้วยังมีโบชัวมาบอกอีกนะ แต่ม เท่านี้แล้วเป็นตั๋วหนังได้ แล้วเล่นตัดไปแล้วมันเหลือแต้ม150จะทำไรได้\n",
      "30 ช่องจ่ายเงินรื้ออกบ้างก็ได้ถ้าไม่มีคนทำ วันเสาร์อาทิตย์รอนานโคตร\n",
      "32 สาขายโสธรเปิดใหม่ พนงแอบโกง   ลูกค้ากุเอง จ่ายหลายใบแล้วทำเนียนว่ามีใบนึงชำรุดใช้ไม่ได้แล้วพอขอคืนก็สลับใบที่รูดใช้แล้วมาแทน แจ้งผู้จัดการขอดูกล้องวงจรปิดไม่ยอมให้ดูเลยต้องขู่ว่าจะแจ้งความถึงยอมคืนให้ แต่ไม่มีคำขอโทษใดๆ จาก พนงติด\n",
      "43 มารยาท คำพูดคำจา ไม่ต้องเพราะหรอกคะแค่ไม่ตะคอก ไม่ชักสีหน้าใสเวลาถามสินค้าอยู่ตรงไหนเวลาไม่เจอ ตอนนี้ก็เลือกที่จะไม่ไปใช้บริการแล้ว มี มาเปิดใกล้บ้าน สบายใจ\n",
      "55 ของมึงไม่ต้องถูกมากก็ได้ เน้นคุณภาพบ้าง ไส้กรอกเน่า แต่ยังไม่หมดอายุงี้อ่ะ สาขาฟอร์จูน ขนมปังขึ้นราแล้วยังวางขายอีก สาขาลาดพร้าว กีวี่หนอนเข้า กะหล่ำปลีเน่าใน ผักบุ้งเน่าแทรกในมัด สาขาอ่อนนุช\n",
      "57 ของป้ายเหลืองพวกผัก เน่าจนไม่รู้จะเน่ายังไง คือทิ้งๆไปก็ได้มั่ง\n",
      "64 ช่องจ่ายเยอะ เยอะเกินพนงใช่ไหม ไม่ระบุสาขานะ เกือบทุกที่ที่ไปมาเลยค่ะ\n",
      "71 เวลาผมซื้อเนื้อสัตว์ช่วยเอาที่คีบหรือช้อนหรืออะไรก็ได้มาวางให้ทีอย่าให้กุต้องใช้มือเปล่าๆจับอีกอย่างจะเก็บช้อนกะที่คีบเร็วไปไหนเพิ่งจะ6โมงเย็นเห็นเอาไปล้างแล้ว\n",
      "77 พนงอะใครดึงหน้าได้นานสุดจะได้ขึ้นเงินเดือนถูกม้ะะะะ เหมือนไปขอฟรีเลย จ่ายตังนะคะจ่ายตัง สติ\n",
      "79 เลิกก๊อปปี้สินค้าแบรนด์ แล้วทำคุณภาพห่วยๆ แม่งเล่นเลย์ซะเหมือนเลย สาดดด\n",
      "82 เปลี่ยนคนดูแลพื้นที่ค่ะมาใหม้ย้าอำนาจไม่ฟังคนอิ่นเอาแต่ความคิดของตัวเองเปนใหญ่ถูกผิดกุไม่สนขอแค่กุถูกคนเดวพอ\n",
      "84 ฝากถึง สาขาแพร่นะคะตอนเช้าๆเลิกมาทอดโดนัทด้านนอกซะทีเถอะค่ะ กลิ่นเหม็นน้ำมันทอดติดผมเผ้าเสื้อผ้า\n",
      "91 โลตัส รัตนาธิเบศร์ แอร์เหม็นมาก เหม็นสาบหนูสุดๆ ตรงโซนอาหารแห้ง บะหมี่กึ่งสำเร็จรูป เดินผ่านก็รู้เลยมีหนู ตรงโซนข้าวสารอีก\n",
      "95 โสตัสเอ็กเพรส สาขาตลาดหนองจอก ระยอง ตู้แช่เย็นฝาตู้ปิดไม่สนิททุกตู้\n",
      "101 คุยกันเสียงดังขณะคิดเงินพูดจาหยาบคายเหี้ยสัตว์ต่อหน้าลค คิดว่าเท่มั้ง\n",
      "104 ของเซลคือเซลเเต่หมดอายุมาหลายเดือนเเล้วยังเซลได้ด้วยหรอของกินไงบางที\n",
      "109 แมลงสาบอยู่ตามเครื่องคิดเงิน ตรงลู่วางของเลยค่ะ เจอทุกรอบ สาขาบางกะปิ\n",
      "112 วันใหนมาตั้งใจมาชื้อหมู หมูหมดเหลือไก่  วันใหนชื้อไก่ไก่หมดได้หมู  ตั้งใจอย่างได้อีกอย่าง\n",
      "123 ถ้ามึงไม่อยากไหว้ ไม่ต้องยกมือไหว้ก้อได้ กูรู้มึงโดนบังคับ ให้ไหว้คนที่ไม่ใช่พ่อใช่แม่ เยสเข้\n",
      "124 บัตรสมาชิก  วัน การ์ด   สะสมแต้ม  แต่ไม่สะดวกเวลาจะใช้งานใช้แต้มสะสม  เพราะมีเงื่อนไขแยกยิบย่อย  ต้องใช้กับสินค้าตัวนั้นตัวนี้  ใช้สำหรับสาขาเล็กใหญ่  เขี้ยวเกิน\n",
      "126 แคชเชียร์ค่ะ ช่วงเวลา21002200 ช่วงเวลาที่ห้างใกล้ปิด แล้วคนจะจ่ายของเยอะมาก ต่อแถวยาวววววว เพราะแคชเชียร์เปิดประมาณ34แคชเชียร์ ทั้งที่มีเป็น10 ทำให้จ่ายเงินได้ล่าช้าามากกกกค่ะอยากให้เปิดเยอะกว่านี้หน่อยต่อแถวนานเกิ๊น\n",
      "128 ในบิลไม่ได้บอกว่าส่วนลดเป็นของสินค้าชิ้นไหน อยากให้บอกหน่อยว่าลดกี่บาทนี้มาจากสินค้าชื่ออะไร\n",
      "131 เอ็กเพรสนี้แลกของแล้วไม่เคยจะโทรบอกเลยหรืออะไรเลยต้องได้ทวง ชอบไม่ให้แสตมป์ เป็นไรมากไหมนี้\n",
      "133 พื้นที่โซนอาหารสดถูบ่อยๆ เถอะค่ะ พื้นเปียกมันทำให้ลื่นนะคะ แล้วมันมีรอยเท้ารอยโคลนลากไปลากมา ดูสกปรกแท้\n",
      "136 เคืองสะสมสแตมป์แลกร่มผ่านมา3ปีจนสาขาย่อยปิดไปแล้วข้ายังไม่ได้ร่มเลยหลอกลวงถามทีไรกำลังผลิตๆที่ดาวดวงใหนรึ\n",
      "140 เครื่องที่ให้แสกนของเองน่ะ อยากให้ปรับตำแหน่งให้มันแสกนจากมือถือได้ด้วยค่ะ บัตรหายไปแล้วแสกนจากมือถือไม่ได้มันติด\n",
      "143 เวลามีคนมาตรวจห้าง อะไรซักอย่างนี่แหละ พนงวิ่งกันโกลาหล โดยเฉพาะ หนพนง  หญ\n",
      "156 เทสโก้ โลตัส สุขุมวิท50 เมื่อไม่กี่วันก่อน หน้าเชสเตอร์ชั้น1 น้ำรั่วลงมาจากช่องแอร์ เหม็นมากแอร์ก็ไม่เย็น\n",
      "158 เลิกให้ส่วนลดแบบวิธีตัดบิล มันทำให้เสียเวลาชำระเงินที่เคาน์เตอร์\n",
      "163 ไปทีไรไม่เห็นมีดอกบัวขาย\n",
      "169 ใช้เครื่องรูดไม่เป็น ไม่รู้จัก\n",
      "171 คืออ่านจนเหนื่อยค่ะ\n",
      "178 ไม่จำเป็นไม่เข้าจริงๆ\n",
      "181 เลิกเก็บกระเป๋าตูสักที5555555\n",
      "182 แมลงสาปให้มันน้อยๆหน่อย\n",
      "192 เส้นสีเขียวยังใช้อยู่ไหม\n",
      "196 เอ็กเพลส พนง เกือบทุกสาขา หน้าไม่รับแขก\n",
      "205 กลิ่น\n",
      "207 อยากให้คิดตัวเร็วๆหน่อยต่อคิวรอจ่ายตังกันยาวชิยหาย\n",
      "209 ส่วนลดที่ให้มา ลดเลยได้ไหม ขี้เกียจเก็บ\n",
      "212 ซื้อไฃ่เจอไข่เน่าเอาไข่ดีๆมาขายบางนะ\n",
      "215 ถามบัตรคลับการ์กูด้วย กูไม่อยากบอกเอง\n",
      "219 หนูวิ่งเป็นของสด\n",
      "220 ตัดบิล กะ ลืมยิงคลับการ์ดให้\n",
      "223 โปรโมชั่นกำกวมมากกกก\n",
      "224 มาตรฐานพลังงานต่ำมากถ้าเทียบกับเซเว่นและบิ๊กซี\n",
      "225 อยากให้ห้องนํ้ามีนํ้า\n",
      "234 แอร์ไม่เย็น\n",
      "237 สลิปจะยาวไปไหน ส่วนลดได้มาก็ไม่เคยใช้\n",
      "239 คูปองไม่ต้องส่งมาที่บ้าน อยากได้ในบิลเลย\n",
      "250 แล้วแต่ที่จริงๆ\n",
      "252 เอกเพรส ซทานสัมฤทธิ์ หน้าหงิกเป็นเล็บขบ\n",
      "255 แอร์ไม่เปิด\n",
      "256 ซื้อของห้าสิบ สลิปยาวเป็นศอก\n",
      "262 แสตมป์คลับการ์ดควรมีแบบเดิมนะ\n"
     ]
    }
   ],
   "source": [
    "comment_widget = widgets.ToggleButtons(\n",
    "    options=[num for num in range(num_cluster)],\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    ")\n",
    "\n",
    "def on_comment_widget_click(change):\n",
    "    clear_output()\n",
    "    display(comment_widget)\n",
    "    for index, value in result[result['predicted_label'] == change['new']]['comment'].iteritems():\n",
    "        if index in initials:\n",
    "            print(\"*\", end=\"\")\n",
    "        print(index, value)\n",
    "\n",
    "comment_widget.observe(on_comment_widget_click, names='index')\n",
    "on_comment_widget_click({'new' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2325497cca5441a6b90642bf34c725c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['ดี', 'เลิก', 'น้ำ', 'เครื่อง', 'ข้าว', 'อี']\n",
      "5 ['อย่า', 'อย่า', 'กี่', 'ปี', 'บังคับ', 'น้อง', 'เชียร์', 'งี่', 'เง่า']\n",
      "10 ['ทำ', 'จ่าย', 'จ่าย', 'ช่อง', 'ช่อง', 'คิว', 'ตัง', 'ตัง', 'หรอ']\n",
      "14 ['สาขา', 'หน้า', 'รถ', 'ตัว', 'ร้าน', 'จอด', 'ชั้น', 'ชั้น', 'กะปิ']\n",
      "18 ['จ่าย', 'ช่อง', 'ช่อง', 'คิว', 'กี่']\n",
      "20 ['หน้า', 'เช็ค', 'งอ', 'สวัสดี']\n",
      "26 ['ปรับปรุง', 'พนง', 'แย่', 'ตะโกน', 'ข้าม', 'หวย', 'พิเศษ', 'พฤติกรรม']\n",
      "29 ['เงิน', 'ซื้อ', 'ดี', 'ถาม', 'อ่ะ', 'หาย', 'ไหม', 'ไหม', 'เล่น']\n",
      "30 ['ทำ', 'เงิน', 'คน', 'จ่าย', 'ช่อง', 'เสาร์', 'อาทิตย์', 'โคตร']\n",
      "32 ['ลูกค้า', 'จ่าย', 'พนง', 'พนง', 'ใบ', 'ใบ', 'ใบ', 'ติด', 'นึง']\n",
      "43 ['เวลา', 'เวลา', 'บริการ', 'สินค้า', 'ถาม', 'มารยาท', 'เจอ', 'ตอน', 'บ้าน']\n",
      "55 ['สาขา', 'สาขา', 'ขาย', 'อ่ะ', 'วาง', 'เน่า', 'เน่า', 'เน่า', 'คุณภาพ']\n",
      "57 ['รู้', 'ผัก', 'เน่า', 'เน่า', 'ทิ้ง', 'ป้ายเหลือง']\n",
      "64 ['สาขา', 'จ่าย', 'พนง', 'ช่อง', 'ไหม', 'ระบุ']\n",
      "71 ['ซื้อ', 'เวลา', 'ผม', 'กะ', 'อย่า', 'วาง', 'มือ', 'เย็น', 'ล้าง']\n",
      "77 ['หน้า', 'เงิน', 'เหมือน', 'จ่าย', 'จ่าย', 'พนง', 'เดือน', 'ตัง', 'ตัง']\n",
      "79 ['ทำ', 'เหมือน', 'สินค้า', 'เลิก', 'แม่ง', 'ห่วย', 'คุณภาพ']\n",
      "82 ['คน', 'คน', 'คน', 'ตัว', 'กุ', 'พื้นที่', 'ฟัง']\n",
      "84 ['สาขา', 'ตอน', 'เลิก', 'ติด', 'ผม', 'กลิ่น', 'เหม็น', 'ฝาก', 'เช้า']\n",
      "91 ['เดิน', 'รู้', 'อาหาร', 'เหม็น', 'ข้าว', 'หนู', 'หนู', 'โซน', 'แห้ง']\n",
      "95 ['สาขา', 'เย็น', 'ตู้', 'ตู้', 'ตู้']\n",
      "101 ['หน้า', 'เงิน', 'คุย', 'พูดจา', 'เสียง', 'เหี้ย', 'สัตว์', 'ลค']\n",
      "104 ['กิน', 'เดือน', 'หรอ', 'เเต่', 'อายุ', 'เเล้ว']\n",
      "109 ['เงิน', 'เจอ', 'เครื่อง', 'วาง', 'รอบ']\n",
      "112 ['หมู', 'หมู', 'หมู', 'ไก่', 'ไก่', 'ไก่', 'ใหน', 'ตั้งใจ', 'ชื้อ']\n",
      "123 ['คน', 'รู้', 'โดน', 'มือ', 'ก้อ', 'บังคับ', 'ไหว้', 'ไหว้', 'ไหว้']\n",
      "124 ['สาขา', 'เวลา', 'งาน', 'สินค้า', 'ตัว', 'ตัว', 'บัตร', 'การ์ด', 'สมาชิก']\n",
      "126 ['ทำ', 'เงิน', 'คน', 'จ่าย', 'จ่าย', 'เวลา', 'เวลา', 'ห้าง', 'แคชเชียร์']\n",
      "128 ['สินค้า', 'สินค้า', 'ลด', 'ลด', 'บิล', 'ชิ้น', 'กี่', 'ชื่อ', 'บาท']\n",
      "131 ['ชอบ', 'เอ็กเพรส', 'แลก', 'ไหม', 'แสตมป์', 'โทร']\n",
      "133 ['ทำ', 'อาหาร', 'ดู', 'สด', 'สกปรก', 'พื้น', 'พื้นที่', 'โซน', 'ลาก']\n",
      "136 ['สาขา', 'ถาม', 'แลก', 'ปี', 'สะสม', 'ร่ม', 'ร่ม', 'ใหน']\n",
      "140 ['ติด', 'บัตร', 'เครื่อง', 'หาย']\n",
      "143 ['คน', 'เวลา', 'พนง', 'ห้าง', 'วิ่ง', 'ตรวจ', 'ซัก']\n",
      "156 ['หน้า', 'น้ำ', 'เย็น', 'กี่', 'เหม็น', 'ชั้น', 'แอร์']\n",
      "158 ['ทำ', 'เงิน', 'เวลา', 'ลด', 'เลิก', 'บิล', 'เคาน์เตอร์', 'วิธี', 'ตัด']\n",
      "163 ['ขาย', 'ดอก']\n",
      "169 []\n",
      "171 ['เหนื่อย']\n",
      "178 []\n",
      "181 ['เลิก', 'สัก', 'ตู']\n",
      "182 []\n",
      "192 ['ไหม', 'สี', 'เขียว']\n",
      "196 ['สาขา', 'หน้า', 'พนง', 'เอ็กเพลส', 'แขก']\n",
      "205 ['กลิ่น']\n",
      "207 ['จ่าย', 'รอ', 'ตัว', 'คิว', 'ตัง']\n",
      "209 ['ลด', 'ลด', 'ไหม', 'ขี้']\n",
      "212 ['ซื้อ', 'ดี', 'เจอ', 'ขาย', 'เน่า']\n",
      "215 ['ถาม', 'บัตร', 'คลับ']\n",
      "219 ['สด', 'วิ่ง', 'หนู']\n",
      "220 ['กะ', 'การ์ด', 'ยิง', 'คลับ']\n",
      "223 ['โปรโมชั่น', 'กกก']\n",
      "224 ['เซเว่น', 'พลังงาน', 'ต่ำ']\n",
      "225 []\n",
      "234 ['เย็น', 'แอร์ไม่']\n",
      "237 ['ลด', 'สลิป']\n",
      "239 ['บ้าน', 'บิล', 'คู', 'ปอง']\n",
      "250 []\n",
      "252 ['หน้า', 'หงิก', 'เอกเพรส', 'เล็บ']\n",
      "255 ['แอร์ไม่']\n",
      "256 ['ซื้อ', 'สิบ', 'ห้า', 'สลิป']\n",
      "262 ['การ์ด', 'แสตมป์', 'คลับ']\n"
     ]
    }
   ],
   "source": [
    "token_widget = widgets.ToggleButtons(\n",
    "    options=[num for num in range(num_cluster)],\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    ")\n",
    "\n",
    "def on_token_widget_click(change):\n",
    "    clear_output()\n",
    "    display(token_widget)\n",
    "    for index, value in result[result['predicted_label'] == change['new']]['tokenized_comment'].iteritems():\n",
    "        print(index, value)\n",
    "\n",
    "token_widget.observe(on_token_widget_click, names='index')\n",
    "on_token_widget_click({'new' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15811388]]\n",
      "['สาขา', 'ลูกค้า', 'โลตัส', 'ถุง', 'นวมินทร์']\n",
      "['ถุง', 'ซื้อ', 'เดิน', 'ซ้อน', 'ผ้า', 'นุ่ม', 'เชียร์', 'ถุงขาด']\n"
     ]
    }
   ],
   "source": [
    "seed = 244\n",
    "compare = 89\n",
    "\n",
    "a = numpy.array(bow_corpus.iloc[seed]).reshape(1, -1)\n",
    "b = numpy.array(bow_corpus.iloc[compare]).reshape(1, -1)\n",
    "print(cosine_similarity(a,b))\n",
    "print(filtered_corpus[seed])\n",
    "print(filtered_corpus[compare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senior-project",
   "language": "python",
   "name": "senior-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
